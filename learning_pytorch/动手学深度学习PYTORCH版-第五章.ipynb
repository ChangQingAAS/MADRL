{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "%matplotlib inline\r\n",
    "import random\r\n",
    "import time \r\n",
    "import torch\r\n",
    "from torch import nn,optim\r\n",
    "from torch.nn import init\r\n",
    "import torchvision\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from IPython import display\r\n",
    "from collections import OrderedDict\r\n",
    "import sys\r\n",
    "import d2lzh as d2l\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "from mpl_toolkits import mplot3d"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. 卷积神经网络 CNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def corr2d(X, K):\r\n",
    "    h, w = K.shape\r\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\r\n",
    "    for i in range(Y.shape[0]):\r\n",
    "        for j in range(Y.shape[1]):\r\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\r\n",
    "\r\n",
    "    return Y\r\n",
    "\r\n",
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\r\n",
    "K = torch.tensor([[0, 1], [2, 3]])\r\n",
    "corr2d(X, K)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.2 二维卷积层\r\n",
    "\r\n",
    "二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏差来得到输出。卷积层的模型参数包括了卷积核和标量偏差。在训练模型的时候，通常我们先对卷积核随机初始化，然后不断迭代卷积核和偏差。\r\n",
    "\r\n",
    "下面基于`corr2d`函数来实现一个自定义的二维卷积层。在构造函数`__init__`里我们声明`weight`和`bias`这两个模型参数。前向计算函数`forward`则是直接调用`corr2d`函数再加上偏差。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "class Conv2D(nn.Module):\r\n",
    "    def __init__(self, kernel_size):\r\n",
    "        super(Conv2D, self).__init__()\r\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\r\n",
    "        self.bias = nn.Parameter(torch.randn(1))\r\n",
    "        \r\n",
    "    def forward(self, x):\r\n",
    "        return corr2d(x, self.weight) + self.bias"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.3 图像中物体边缘检测\r\n",
    "\r\n",
    "下面我们来看一个卷积层的简单应用：检测图像中物体的边缘，即找到像素变化的位置。\r\n",
    "\r\n",
    "首先我们构造一张$6\\times 8$的图像（即高和宽分别为6像素和8像素的图像）。它中间4列为黑（0），其余为白（1）。\r\n",
    "\r\n",
    "然后我们构造一个高和宽分别为1和2的卷积核`K`。当它与输入做互相关运算时，如果横向相邻元素相同，输出为0；否则输出为非0。\r\n",
    "\r\n",
    "由此，我们可以看出，卷积层可通过重复使用卷积核有效地表征局部空间。\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "X = torch.ones(6, 8)\r\n",
    "X[:, 2:6] = 0\r\n",
    "K = torch.tensor([[1, -1]])\r\n",
    "Y = corr2d(X, K)\r\n",
    "X,Y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "         [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "         [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "         [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "         [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "         [1., 1., 0., 0., 0., 0., 1., 1.]]),\n",
       " tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "         [ 0.,  1.,  0.,  0.,  0., -1.,  0.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.4 通过数据学习核数组\r\n",
    "\r\n",
    "使用物体边缘检测中的输入数据`X`和输出数据`Y`来学习我们构造的核数组`K`。\r\n",
    "\r\n",
    "首先构造一个卷积层，其卷积核将被初始化成随机数组。接下来在每一次迭代中，我们使用平方误差来比较`Y`和卷积层的输出，然后计算梯度来更新权重。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# 构造一个核数组形状是(1, 2)的二维卷积层\r\n",
    "conv2d = Conv2D(kernel_size=(1, 2))\r\n",
    "\r\n",
    "step = 100\r\n",
    "lr = 0.01\r\n",
    "for i in range(step):\r\n",
    "    Y_hat = conv2d(X)\r\n",
    "    l = ((Y_hat - Y) ** 2).sum()\r\n",
    "    l.backward()\r\n",
    "    \r\n",
    "    # 梯度下降\r\n",
    "    conv2d.weight.data -= lr * conv2d.weight.grad\r\n",
    "    conv2d.bias.data -= lr * conv2d.bias.grad\r\n",
    "    \r\n",
    "    # 梯度清0\r\n",
    "    conv2d.weight.grad.fill_(0)\r\n",
    "    conv2d.bias.grad.fill_(0)\r\n",
    "\r\n",
    "    if (i + 1) % 25 == 0:\r\n",
    "        print('Step %d, loss %.10f' % (i + 1, l.item()))\r\n",
    "\r\n",
    "# 训练结束后，看看weight和bias\r\n",
    "print(\"weight: \", conv2d.weight.data)\r\n",
    "print(\"bias: \", conv2d.bias.data)\r\n",
    "\r\n",
    "# 可以看到，学到的卷积核的权重参数与我们之前定义的核数组`K`较接近，而偏置参数接近0。"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bias  Parameter containing:\n",
      "tensor([-0.4042], requires_grad=True)\n",
      "Step 25, loss 0.1945903301\n",
      "Step 50, loss 0.0003255384\n",
      "Step 75, loss 0.0000005452\n",
      "Step 100, loss 0.0000000009\n",
      "weight:  tensor([[ 1.0000, -1.0000]])\n",
      "bias:  tensor([-1.4049e-13])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1.5 互相关运算和卷积运算\r\n",
    "\r\n",
    "![](./img/5.1.png)\r\n",
    "\r\n",
    "实际上，卷积运算与互相关运算类似。**为了得到卷积运算的输出，我们只需将核数组左右翻转并上下翻转，再与输入数组做互相关运算**。可见，卷积运算和互相关运算虽然类似，但如果它们使用相同的核数组，对于同一个输入，输出往往并不相同。\r\n",
    "\r\n",
    "那么，你也许会好奇卷积层为何能使用互相关运算替代卷积运算。其实，在深度学习中核数组都是学出来的：卷积层无论使用互相关运算或卷积运算都不影响模型预测时的输出。为了解释这一点，假设卷积层使用互相关运算学出图5.1中的核数组。设其他条件不变，使用卷积运算学出的核数组即图5.1中的核数组按上下、左右翻转。也就是说，图5.1中的输入与学出的已翻转的核数组再做卷积运算时，依然得到图5.1中的输出。为了与大多数深度学习文献一致，如无特别说明，本书中提到的卷积运算均指互相关运算。\r\n",
    "\r\n",
    "\r\n",
    "### 5.1.6 特征图和感受野\r\n",
    "\r\n",
    "二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素$x$的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做$x$的感受野（receptive field）。以图5.1为例，输入中阴影部分的四个元素是输出中阴影部分元素的感受野。我们将图5.1中形状为$2 \\times 2$的输出记为$Y$，并考虑一个更深的卷积神经网络：将$Y$与另一个形状为$2 \\times 2$的核数组做互相关运算，输出单个元素$z$。那么，$z$在$Y$上的感受野包括$Y$的全部四个元素，在输入上的感受野包括其中全部9个元素。可见，我们可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。\r\n",
    "\r\n",
    "我们常使用“元素”一词来描述数组或矩阵中的成员。在神经网络的术语中，这些元素也可称为“单元”。当含义明确时，本书不对这两个术语做严格区分。\r\n",
    "\r\n",
    "\r\n",
    "### 小结\r\n",
    "\r\n",
    "* 二维卷积层的核心计算是二维互相关运算。在最简单的形式下，它对二维输入数据和卷积核做互相关运算然后加上偏差。\r\n",
    "* 我们可以设计卷积核来检测图像中的边缘。\r\n",
    "* 我们可以通过数据来学习卷积核。 \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.2 填充和步幅\r\n",
    "\r\n",
    "在上一节的例子里，我们使用高和宽为3的输入与高和宽为2的卷积核得到高和宽为2的输出。一般来说，假设输入形状是$n_h\\times n_w$，卷积核窗口形状是$k_h\\times k_w$，那么输出形状将会是\r\n",
    "\r\n",
    "$$(n_h-k_h+1) \\times (n_w-k_w+1).$$\r\n",
    "\r\n",
    "所以卷积层的输出形状由输入形状和卷积核窗口形状决定。本节我们将介绍卷积层的两个超参数，即填充和步幅。它们可以对给定形状的输入和卷积核改变输出形状。\r\n",
    "\r\n",
    "### 5.2.1 填充\r\n",
    "\r\n",
    "填充（padding）是指在输入高和宽的两侧填充元素（通常是0元素）。图5.2里我们在原输入高和宽的两侧分别添加了值为0的元素，使得输入高和宽从3变成了5，并导致输出高和宽由2增加到4。图5.2中的阴影部分为第一个输出元素及其计算所使用的输入和核数组元素：$0\\times0+0\\times1+0\\times2+0\\times3=0$。\r\n",
    " \r\n",
    "\r\n",
    "![](./img/chapter5/5.2_conv_pad.png)\r\n",
    "\r\n",
    "\r\n",
    "一般来说，如果在高的两侧一共填充$p_h$行，在宽的两侧一共填充$p_w$列，那么输出形状将会是\r\n",
    "\r\n",
    "$$(n_h-k_h+p_h+1)\\times(n_w-k_w+p_w+1),$$\r\n",
    "\r\n",
    "也就是说，输出的高和宽会分别增加$p_h$和$p_w$。\r\n",
    "\r\n",
    "在很多情况下，我们会设置$p_h=k_h-1$和$p_w=k_w-1$来使输入和输出具有相同的高和宽。这样会方便在构造网络时推测每个层的输出形状。假设这里$k_h$是奇数，我们会在高的两侧分别填充$p_h/2$行。如果$k_h$是偶数，一种可能是在输入的顶端一侧填充$\\lceil p_h/2\\rceil$行，而在底端一侧填充$\\lfloor p_h/2\\rfloor$行。在宽的两侧填充同理。\r\n",
    "\r\n",
    "卷积神经网络经常使用奇数高宽的卷积核，如1、3、5和7，所以两端上的填充个数相等。对任意的二维数组`X`，设它的第`i`行第`j`列的元素为`X[i,j]`。\r\n",
    "\r\n",
    "当两端上的填充个数相等，并使输入和输出具有相同的高和宽时，我们就知道输出`Y[i,j]`是由输入以`X[i,j]`为中心的窗口同卷积核进行互相关计算得到的。\r\n",
    "\r\n",
    "下面的例子里我们创建一个高和宽为3的二维卷积层，然后设输入高和宽两侧的填充数分别为1。给定一个高和宽为8的输入，我们发现输出的高和宽也是8。\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# 定义⼀个函数来计算卷积层。它对输⼊和输出做相应的升维和降维\r\n",
    "def comp_conv2d(conv2d, X):\r\n",
    "    # (1, 1)代表批量⼤⼩和通道数（“多输⼊通道和多输出通道”⼀节将介绍）均为1\r\n",
    "    X = X.view((1, 1) + X.shape)\r\n",
    "    Y = conv2d(X)\r\n",
    "    return Y.view(Y.shape[2:]) # 排除不关⼼的前两维：批量和通道\r\n",
    "\r\n",
    "\r\n",
    "# 注意这⾥是两侧分别填充1⾏或列，所以在两侧⼀共填充2⾏或列\r\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3,padding=1)\r\n",
    "X = torch.rand(8, 8)\r\n",
    "comp_conv2d(conv2d, X).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# 当卷积核的⾼和宽不同时，我们也可以通过设置⾼和宽上不同的填充数使输出和输⼊具有相同的⾼和宽\r\n",
    "\r\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(5, 3), padding=(2, 1))\r\n",
    "comp_conv2d(conv2d, X).shape\r\n",
    "# (8-5+2*2+1) * (8-3+2*1+1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2.2 步幅\r\n",
    "\r\n",
    " 将每次滑动的行数和列数称为步幅（stride）。\r\n",
    "\r\n",
    "目前我们看到的例子里，在高和宽两个方向上步幅均为1。我们也可以使用更大步幅。图5.3展示了在高上步幅为3、在宽上步幅为2的二维互相关运算。可以看到，输出第一列第二个元素时，卷积窗口向下滑动了3行，而在输出第一行第二个元素时卷积窗口向右滑动了2列。当卷积窗口在输入上再向右滑动2列时，由于输入元素无法填满窗口，无结果输出。图5.3中的阴影部分为输出元素及其计算所使用的输入和核数组元素：$0\\times0+0\\times1+1\\times2+2\\times3=8$、$0\\times0+6\\times1+0\\times2+0\\times3=6$。\r\n",
    "\r\n",
    "![](./img/5.3.png)\r\n",
    "\r\n",
    "一般来说，当高上步幅为$s_h$，宽上步幅为$s_w$时，输出形状为\r\n",
    "\r\n",
    "$$\\lfloor(n_h-k_h+p_h+s_h)/s_h\\rfloor \\times \\lfloor(n_w-k_w+p_w+s_w)/s_w\\rfloor.$$\r\n",
    "\r\n",
    "如果设置$p_h=k_h-1$和$p_w=k_w-1$，那么输出形状将简化为$\\lfloor(n_h+s_h-1)/s_h\\rfloor \\times \\lfloor(n_w+s_w-1)/s_w\\rfloor$。更进一步，如果输入的高和宽能分别被高和宽上的步幅整除，那么输出形状将是$(n_h/s_h) \\times (n_w/s_w)$。\r\n",
    "\r\n",
    "下面我们令高和宽上的步幅均为2，从而使输入的高和宽减半。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\r\n",
    "comp_conv2d(conv2d, X).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "为了表述简洁，当输入的高和宽两侧的填充数分别为$p_h$和$p_w$时，我们称填充为$(p_h, p_w)$。特别地，当$p_h = p_w = p$时，填充为$p$。当在高和宽上的步幅分别为$s_h$和$s_w$时，我们称步幅为$(s_h, s_w)$。特别地，当$s_h = s_w = s$时，步幅为$s$。在默认情况下，填充为0，步幅为1。\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "### 小结\r\n",
    "\r\n",
    "* 填充可以增加输出的高和宽。这常用来使输出与输入具有相同的高和宽。\r\n",
    "* 步幅可以减小输出的高和宽，例如输出的高和宽仅为输入的高和宽的$1/n$（$n$为大于1的整数）。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.3 多输入通道和多输出通道\r\n",
    "\r\n",
    "前面两节里我们用到的输入和输出都是二维数组，但真实数据的维度经常更高。例如，彩色图像在高和宽2个维度外还有RGB（红、绿、蓝）3个颜色通道。假设彩色图像的高和宽分别是$h$和$w$（像素），那么它可以表示为一个$3\\times h\\times w$的多维数组。我们将大小为3的这一维称为通道（channel）维。本节我们将介绍含多个输入通道或多个输出通道的卷积核。\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "### 5.3.1 多输入通道\r\n",
    "\r\n",
    "当输入数据含多个通道时，我们需要构造一个输入通道数与输入数据的通道数相同的卷积核，从而能够与含多通道的输入数据做互相关运算。假设输入数据的通道数为$c_i$，那么卷积核的输入通道数同样为$c_i$。设卷积核窗口形状为$k_h\\times k_w$。当$c_i=1$时，我们知道卷积核只包含一个形状为$k_h\\times k_w$的二维数组。当$c_i > 1$时，我们将会为每个输入通道各分配一个形状为$k_h\\times k_w$的核数组。把这$c_i$个数组在输入通道维上连结，即得到一个形状为$c_i\\times k_h\\times k_w$的卷积核。由于输入和卷积核各有$c_i$个通道，我们可以在各个通道上对输入的二维数组和卷积核的二维核数组做互相关运算，再将这$c_i$个互相关运算的二维输出按通道相加，得到一个二维数组。这就是含多个通道的输入数据与多输入通道的卷积核做二维互相关运算的输出。\r\n",
    "\r\n",
    "图5.4展示了含2个输入通道的二维互相关计算的例子。在每个通道上，二维输入数组与二维核数组做互相关运算，再按通道相加即得到输出。图5.4中阴影部分为第一个输出元素及其计算所使用的输入和核数组元素：$(1\\times1+2\\times2+4\\times3+5\\times4)+(0\\times0+1\\times1+3\\times2+4\\times3)=56$。\r\n",
    "\r\n",
    "![](./img/5.4.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# 实现含多个输⼊通道的互相关运算\r\n",
    "# 思路：只需要对每个通道做互相关运算，然后通过`add_n`函数来进行累加。\r\n",
    "\r\n",
    "\r\n",
    "def corr2d_multi_in(X, K):\r\n",
    "    # 沿着X和K的第0维（通道维）分别计算再相加\r\n",
    "    res = d2l.corr2d(X[0, :, :], K[0, :, :])\r\n",
    "    for i in range(1, X.shape[0]):\r\n",
    "        res += d2l.corr2d(X[i, :, :], K[i, :, :])\r\n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "X = torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],\r\n",
    "              [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\r\n",
    "K = torch.tensor([[[0, 1], [2, 3]], [[1, 2], [3, 4]]])\r\n",
    "\r\n",
    "corr2d_multi_in(X, K)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " \r\n",
    "### 5.3.2 多输出通道\r\n",
    "\r\n",
    "当输入通道有多个时，因为我们对各个通道的结果做了累加，所以不论输入通道数是多少，输出通道数总是为1。设卷积核输入通道数和输出通道数分别为$c_i$和$c_o$，高和宽分别为$k_h$和$k_w$。如果希望得到含多个通道的输出，我们可以为每个输出通道分别创建形状为$c_i\\times k_h\\times k_w$的核数组。将它们在输出通道维上连结，卷积核的形状即$c_o\\times c_i\\times k_h\\times k_w$。在做互相关运算时，每个输出通道上的结果由卷积核在该输出通道上的核数组与整个输入数组计算而来。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# 实现⼀个互相关运算函数来计算多个通道的输出。\r\n",
    "\r\n",
    "def corr2d_multi_in_out(X, K):\r\n",
    "    # 对K的第0维遍历，每次同输入X做互相关计算。所有结果使用stack函数合并在一起\r\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# 将核数组`K`同`K+1`（`K`中每个元素加一）和`K+2`连结在一起来构造一个输出通道数为3的卷积核。\r\n",
    "K = torch.stack([K, K + 1, K + 2])\r\n",
    "K.shape # torch.Size([3, 2, 2, 2])\r\n",
    "corr2d_multi_in_out(X, K)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.3.3 $1\\times 1$卷积层\r\n",
    "\r\n",
    "最后我们讨论卷积窗口形状为$1\\times 1$（$k_h=k_w=1$）的多通道卷积层。我们通常称之为$1\\times 1$卷积层，并将其中的卷积运算称为$1\\times 1$卷积。因为使用了最小窗口，$1\\times 1$卷积失去了卷积层可以识别高和宽维度上相邻元素构成的模式的功能。实际上，$1\\times 1$卷积的主要计算发生在通道维上。图5.5展示了使用输入通道数为3、输出通道数为2的$1\\times 1$卷积核的互相关计算。值得注意的是，输入和输出具有相同的高和宽。输出中的每个元素来自输入中在高和宽上相同位置的元素在不同通道之间的按权重累加。假设我们将通道维当作特征维，将高和宽维度上的元素当成数据样本，**那么$1\\times 1$卷积层的作用与全连接层等价**。\r\n",
    "\r\n",
    "![](./img/5.5.png)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# 使用全连接层中的矩阵乘法来实现1 X 1 卷积\r\n",
    "#这里需要在矩阵乘法运算前后对数据形状做一些调整\r\n",
    "\r\n",
    "def corr2d_multi_in_out_1x1(X, K):\r\n",
    "    c_i, h, w = X.shape\r\n",
    "    c_o = K.shape[0]\r\n",
    "    X = X.view(c_i, h * w)\r\n",
    "    K = K.view(c_o, c_i)\r\n",
    "    Y = torch.mm(K, X)  # 全连接层的矩阵乘法\r\n",
    "    return Y.view(c_o, h, w)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "经验证，做$1\\times 1$卷积时，以上函数与之前实现的互相关运算函数`corr2d_multi_in_out`等价。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "X = torch.rand(3, 3, 3)\r\n",
    "K = torch.rand(2, 3, 1, 1)\r\n",
    "\r\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\r\n",
    "Y2 = corr2d_multi_in_out(X, K)\r\n",
    "\r\n",
    "(Y1 - Y2).norm().item() < 1e-6 # true\r\n",
    "(Y1 == Y2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[True, True, True],\n",
       "         [True, True, True],\n",
       "         [True, True, True]],\n",
       "\n",
       "        [[True, True, True],\n",
       "         [True, True, True],\n",
       "         [True, True, True]]])"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "在之后的模型里我们将会看到$1\\times 1$卷积层被当作保持高和宽维度形状不变的全连接层使用。于是，我们可以通过调整网络层之间的通道数来控制模型复杂度。\r\n",
    "\r\n",
    "\r\n",
    "## 小结\r\n",
    "\r\n",
    "* 使用多通道可以拓展卷积层的模型参数。\r\n",
    "* 假设将通道维当作特征维，将高和宽维度上的元素当成数据样本，那么$1\\times 1$卷积层的作用与全连接层等价。\r\n",
    "* $1\\times 1$卷积层通常用来调整网络层之间的通道数，并控制模型复杂度。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.4 池化层\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "回忆一下，在5.1节（二维卷积层）里介绍的图像物体边缘检测应用中，我们构造卷积核从而精确地找到了像素变化的位置。设任意二维数组`X`的`i`行`j`列的元素为`X[i, j]`。如果我们构造的卷积核输出`Y[i, j]=1`，那么说明输入中`X[i, j]`和`X[i, j+1]`数值不一样。这可能意味着物体边缘通过这两个元素之间。但实际图像里，我们感兴趣的物体不会总出现在固定位置：即使我们连续拍摄同一个物体也极有可能出现像素位置上的偏移。这会导致同一个边缘对应的输出可能出现在卷积输出`Y`中的不同位置，进而对后面的模式识别造成不便。\r\n",
    "\r\n",
    "在本节中我们介绍池化（pooling）层，它的提出是**为了缓解卷积层对位置的过度敏感性**。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.4.1 二维最大池化层和平均池化层\r\n",
    "\r\n",
    "同卷积层一样，池化层每次对输入数据的一个固定形状窗口（又称池化窗口）中的元素计算输出。不同于卷积层里计算输入和核的互相关性，池化层直接计算池化窗口内元素的最大值或者平均值。该运算也分别叫做最大池化或平均池化。在二维最大池化中，池化窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，依次在输入数组上滑动。当池化窗口滑动到某一位置时，窗口中的输入子数组的最大值即输出数组中相应位置的元素。\r\n",
    "\r\n",
    "\r\n",
    "让我们再次回到本节开始提到的物体边缘检测的例子。现在我们将卷积层的输出作为$2\\times 2$最大池化的输入。设该卷积层输入是`X`、池化层输出为`Y`。无论是`X[i, j]`和`X[i, j+1]`值不同，还是`X[i, j+1]`和`X[i, j+2]`不同，池化层输出均有`Y[i, j]=1`。也就是说，使用$2\\times 2$最大池化层时，只要卷积层识别的模式在高和宽上移动不超过一个元素，我们依然可以将它检测出来。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def pool2D(X,pool_size,mode='max'):\r\n",
    "    X= X.float()\r\n",
    "    p_h,p_w = pool_size\r\n",
    "    Y = torch.zeros(X.shape[0] - p_h + 1, X.shape[1] - p_w +1)\r\n",
    "    for i in range(Y.shape[0]):\r\n",
    "        for j in range(Y.shape[1]):\r\n",
    "            if mode == 'max':\r\n",
    "                Y[i,j] = X[i:i+p_h,j:j+p_w].max()\r\n",
    "            elif mode == 'avg':\r\n",
    "                Y[i,j] = X[i:i+p_h,j:j+p_w].mean()\r\n",
    "    \r\n",
    "    return Y\r\n",
    "\r\n",
    "# X = torch.tensor([[0,1,2],[3,4,5],[6,7,8]])\r\n",
    "# pool2D(X,(2,2),'avg')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "通过`nn`模块里的二维最大池化层`MaxPool2d`来演示池化层填充和步幅的工作机制。\r\n",
    "\r\n",
    "默认情况下，`MaxPool2d`实例里步幅和池化窗口形状相同。下面使用形状为(3, 3)的池化窗口，默认获得形状为(3, 3)的步幅。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "X = torch.arange(16,dtype=torch.float).view((1,1,4,4))\r\n",
    "pool2d = nn.MaxPool2d(3)\r\n",
    "pool2d(X) # tensor([[[[10.]]]])\r\n",
    "\r\n",
    "pool2d = nn.MaxPool2d((2,4),padding=(1,2),stride=(2,4))\r\n",
    "pool2d(X)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  3.],\n",
       "          [ 9., 11.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.4.3 多通道\r\n",
    "\r\n",
    "在处理多通道输入数据时，**池化层对每个输入通道分别池化，而不是像卷积层那样将各通道的输入按通道相加**。这意味着池化层的输出通道数与输入通道数相等。下面将数组`X`和`X+1`在通道维上连结来构造通道数为2的输入。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "X = torch.arange(16,dtype=torch.float).view((1,1,4,4))\r\n",
    "X = torch.cat((X,X+1),dim=1)\r\n",
    "X\r\n",
    "# 池化后，我们发现输出通道数仍然是2。\r\n",
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\r\n",
    "pool2d(X)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 小结\r\n",
    "\r\n",
    "* 最大池化和平均池化分别取池化窗口中输入元素的最大值和平均值作为输出。\r\n",
    "* 池化层的一个主要作用是缓解卷积层对位置的过度敏感性。\r\n",
    "* 可以指定池化层的填充和步幅。\r\n",
    "* 池化层的输出通道数跟输入通道数相同。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.5 卷积神经网络（LeNet）\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "在3.9节（多层感知机的从零开始实现）里我们构造了一个含单隐藏层的多层感知机模型来对Fashion-MNIST数据集中的图像进行分类。每张图像高和宽均是28像素。我们将图像中的像素逐行展开，得到长度为784的向量，并输入进全连接层中。然而，这种分类方法有一定的局限性。\r\n",
    "\r\n",
    "1. 图像在同一列邻近的像素在这个向量中可能相距较远。它们构成的模式可能难以被模型识别。\r\n",
    "2. 对于大尺寸的输入图像，使用全连接层容易造成模型过大。假设输入是高和宽均为1000像素的彩色照片（含3个通道）。即使全连接层输出个数仍是256，该层权重参数的形状是$3,000,000\\times 256$：它占用了大约3 GB的内存或显存。这带来过复杂的模型和过高的存储开销。\r\n",
    "\r\n",
    "卷积层尝试解决这两个问题。一方面，卷积层保留输入形状，使图像的像素在高和宽两个方向上的相关性均可能被有效识别；另一方面，卷积层通过滑动窗口将同一卷积核与不同位置的输入重复计算，从而避免参数尺寸过大。\r\n",
    "\r\n",
    " 本节里我们将介绍一个早期用来识别手写数字图像的卷积神经网络：LeNet  。 LeNet展示了通过梯度下降训练卷积神经网络可以达到手写数字识别在当时最先进的结果。 "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.5.1 LeNet模型\r\n",
    "\r\n",
    "LeNet分为卷积层块和全连接层块两个部分。下面我们分别介绍这两个模块。\r\n",
    "\r\n",
    "卷积层块里的基本单位是卷积层后接最大池化层：卷积层用来识别图像里的空间模式，如线条和物体局部，之后的最大池化层则用来降低卷积层对位置的敏感性。卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使用$5\\times 5$的窗口，并在输出上使用sigmoid激活函数。第一个卷积层输出通道数为6，第二个卷积层输出通道数则增加到16。这是因为第二个卷积层比第一个卷积层的输入的高和宽要小，所以增加输出通道使两个卷积层的参数尺寸类似。卷积层块的两个最大池化层的窗口形状均为$2\\times 2$，且步幅为2。由于池化窗口与步幅形状相同，池化窗口在输入上每次滑动所覆盖的区域互不重叠。\r\n",
    "\r\n",
    "卷积层块的输出形状为(批量大小, 通道, 高, 宽)。当卷积层块的输出传入全连接层块时，全连接层块会将小批量中每个样本变平（flatten）。也就是说，全连接层的输入形状将变成二维，其中第一维是小批量中的样本，第二维是每个样本变平后的向量表示，且向量长度为通道、高和宽的乘积。全连接层块含3个全连接层。它们的输出个数分别是120、84和10，其中10为输出的类别个数。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# 下面我们通过`Sequential`类来实现LeNet模型。\r\n",
    "\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "class LeNet(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(LeNet,self).__init__()\r\n",
    "        self.conv = nn.Sequential(\r\n",
    "            nn.Conv2d(1,6,5),\r\n",
    "            nn.Sigmoid(),\r\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\r\n",
    "            nn.Conv2d(6, 16, 5),\r\n",
    "            nn.Sigmoid(),\r\n",
    "            nn.MaxPool2d(2, 2)\r\n",
    "        )\r\n",
    "        self.fc = nn.Sequential(\r\n",
    "            nn.Linear(16*4*4, 120),\r\n",
    "            nn.Sigmoid(),\r\n",
    "            nn.Linear(120, 84),\r\n",
    "            nn.Sigmoid(),\r\n",
    "            nn.Linear(84, 10)\r\n",
    "        )\r\n",
    "    def forward(self, img):\r\n",
    "        feature = self.conv(img)\r\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\r\n",
    "        return output\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# 查看每层的形状\r\n",
    "\r\n",
    "net = LeNet()\r\n",
    "print(net)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LeNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到，在卷积层块中输入的高和宽在逐层减小。卷积层由于使用高和宽均为5的卷积核，从而将高和宽分别减小4，而池化层则将高和宽减半，但通道数则从1增加到16。全连接层则逐层减少输出个数，直到变成图像的类别数10。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.5.2 获取数据和训练模型\r\n",
    "\r\n",
    "下面我们来实验LeNet模型。实验中，我们仍然使用Fashion-MNIST作为训练数据集。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "batch_size = 256\r\n",
    "train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# 对3.6节（softmax回归的从零开始实现）中描述的`evaluate_accuracy`函数略作修改，使其支持GPU计算。\r\n",
    "\r\n",
    "def evaluate_accuracy(data_iter,net,device = None):\r\n",
    "    if device is None and isinstance(net,torch.nn.Module):\r\n",
    "        # 如果没指定定device就是用net的device\r\n",
    "        device = list(net.parameters())[0].device\r\n",
    "    \r\n",
    "    acc_sum = 0.0\r\n",
    "    n = 0\r\n",
    "    with torch.no_grad():\r\n",
    "        for X,y in data_iter:\r\n",
    "            if isinstance(net,torch.nn.Module):\r\n",
    "                net.eval() # 评估模式，这会关闭dropout\r\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\r\n",
    "                net.train() # 改回训练模式\r\n",
    "            else: # 自定义的模型，不考虑GPU\r\n",
    "                if('is_training' in net.__code__.co_varnames):\r\n",
    "                # 如果有is_training参数\r\n",
    "                    # 将is_trainging设置为False\r\n",
    "                    acc_sum += (net(X,is_training=False).argmax(dim=1) == y).float().sum().item()\r\n",
    "                else:\r\n",
    "                    acc_sum += (net(X).argmac(dim=1) == y).float().sum().item()\r\n",
    "            n += y.shape[0]\r\n",
    "        return acc_sum / n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "def train_ch5(net,train_iter,test_iter,batch_size,optimizer,device,num_epochs):\r\n",
    "    net = net.to(device)\r\n",
    "    print(\"training on \",device)\r\n",
    "    loss = torch.nn.CrossEntropyLoss()\r\n",
    "    for epoch in range(num_epochs):\r\n",
    "        train_l_sum,train_acc_sum,n,batch_count = 0.0,0.0,0.0,0\r\n",
    "        start = time.time()\r\n",
    "        for X,y in train_iter:\r\n",
    "            X = X.to(device)\r\n",
    "            y = y.to(device)\r\n",
    "            y_hat = net(X)\r\n",
    "            l = loss(y_hat,y)\r\n",
    "            optimizer.zero_grad()\r\n",
    "            l.backward()\r\n",
    "            train_l_sum += l.cpu().item()\r\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\r\n",
    "            n += y.shape[0]\r\n",
    "            batch_count += 1\r\n",
    "        test_acc = evaluate_accuracy(test_iter,net)\r\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec' % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "lr = 0.001\r\n",
    "num_epochs = 5\r\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr = lr)\r\n",
    "train_ch5(net,train_iter,test_iter,batch_size,optimizer,device,num_epochs)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training on  cpu\n",
      "epoch 1, loss 2.3500, train acc 0.100, test acc 0.100, time 32.4 sec\n",
      "epoch 2, loss 2.3498, train acc 0.100, test acc 0.100, time 47.9 sec\n",
      "epoch 3, loss 2.3498, train acc 0.100, test acc 0.100, time 53.7 sec\n",
      "epoch 4, loss 2.3499, train acc 0.100, test acc 0.100, time 45.3 sec\n",
      "epoch 5, loss 2.3499, train acc 0.100, test acc 0.100, time 42.5 sec\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 小结\r\n",
    "\r\n",
    "* LeNet交替使用卷积层和最大池化层后接全连接层来进行图像分类。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.6 深度卷积神经网络（AlexNet）\r\n",
    "\r\n",
    " 虽然LeNet可以在早期的小数据集上取得好的成绩，但是在更大的真实数据集上的表现并不尽如人意。一方面，神经网络计算复杂。 。因此，训练一个多通道、多层和有大量参数的卷积神经网络在当年很难完成。另一方面，当年研究者还没有大量深入研究参数初始化和非凸优化算法等诸多领域，导致复杂的神经网络的训练通常较困难。\r\n",
    "\r\n",
    "我们在上一节看到，神经网络可以直接基于图像的原始像素进行分类。这种称为端到端（end-to-end）的方法节省了很多中间步骤。然而，在很长一段时间里更流行的是研究者通过勤劳与智慧所设计并生成的手工特征。这类图像分类研究的主要流程是：\r\n",
    "\r\n",
    "1. 获取图像数据集；\r\n",
    "2. 使用已有的特征提取函数生成图像的特征；\r\n",
    "3. 使用机器学习模型对图像的特征分类。\r\n",
    "\r\n",
    "当时认为的机器学习部分仅限最后这一步。如果那时候跟机器学习研究者交谈，他们会认为机器学习既重要又优美。优雅的定理证明了许多分类器的性质。机器学习领域生机勃勃、严谨而且极其有用。然而，如果跟计算机视觉研究者交谈，则是另外一幅景象。他们会告诉你图像识别里“不可告人”的现实是：计算机视觉流程中真正重要的是数据和特征。也就是说，使用较干净的数据集和较有效的特征甚至比机器学习模型的选择对图像分类结果的影响更大。\r\n",
    "\r\n",
    "\r\n",
    "### 5.6.1 学习特征表示\r\n",
    "\r\n",
    " 在相当长的时间里，特征都是基于各式各样手工设计的函数从数据中提取的。事实上，不少研究者通过提出新的特征提取函数不断改进图像分类结果。 \r\n",
    "\r\n",
    "然而，另一些研究者则持异议。他们认为特征本身也应该由学习得来。他们还相信，为了表征足够复杂的输入，特征本身应该分级表示。持这一想法的研究者相信，多层神经网络可能可以学得数据的多级表征，并逐级表示越来越抽象的概念或模式。以图像分类为例，并回忆5.1节（二维卷积层）中物体边缘检测的例子。在多层神经网络中，图像的第一级的表示可以是在特定的位置和⻆度是否出现边缘；而第二级的表示说不定能够将这些边缘组合出有趣的模式，如花纹；在第三级的表示中，也许上一级的花纹能进一步汇合成对应物体特定部位的模式。这样逐级表示下去，最终，模型能够较容易根据最后一级的表示完成分类任务。需要强调的是，输入的逐级表示由多层模型中的参数决定，而这些参数都是学出来的。\r\n",
    "\r\n",
    "尽管一直有一群执着的研究者不断钻研，试图学习视觉数据的逐级表征，然而很长一段时间里这些野心都未能实现。这其中有诸多因素值得我们一一分析。\r\n",
    "\r\n",
    "\r\n",
    "#### 5.6.1.1 缺失要素一：数据\r\n",
    "\r\n",
    "包含许多特征的深度模型需要大量的有标签的数据才能表现得比其他经典方法更好。限于早期计算机有限的存储和90年代有限的研究预算，大部分研究只基于小的公开数据集。例如，不少研究论文基于加州大学欧文分校（UCI）提供的若干个公开数据集，其中许多数据集只有几百至几千张图像。这一状况在2010年前后兴起的大数据浪潮中得到改善。特别是，2009年诞生的ImageNet数据集包含了1,000大类物体，每类有多达数千张不同的图像。这一规模是当时其他公开数据集无法与之相提并论的。ImageNet数据集同时推动计算机视觉和机器学习研究进入新的阶段，使此前的传统方法不再有优势。\r\n",
    "\r\n",
    "\r\n",
    "#### 5.6.1.2 缺失要素二：硬件\r\n",
    "\r\n",
    "深度学习对计算资源要求很高。早期的硬件计算能力有限，这使训练较复杂的神经网络变得很困难。然而，通用GPU的到来改变了这一格局。很久以来，GPU都是为图像处理和计算机游戏设计的，尤其是针对大吞吐量的矩阵和向量乘法从而服务于基本的图形变换。值得庆幸的是，这其中的数学表达与深度网络中的卷积层的表达类似。通用GPU这个概念在2001年开始兴起，涌现出诸如OpenCL和CUDA之类的编程框架。这使得GPU也在2010年前后开始被机器学习社区使用。\r\n",
    "\r\n",
    "\r\n",
    "### 5.6.2 AlexNet\r\n",
    "\r\n",
    "2012年 AlexNet使用了8层卷积神经网络，并以很大的优势赢得了ImageNet 2012图像识别挑战赛。它首次证明了学习到的特征可以超越手工设计的特征，从而一举打破计算机视觉研究的前状。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "AlexNet将sigmoid激活函数改成了更加简单的ReLU激活函数。⼀⽅⾯，ReLU激活函数的计算更\r\n",
    "简单，例如它并没有sigmoid激活函数中的求幂运算。另⼀⽅⾯，ReLU激活函数在不同的参数初始化⽅\r\n",
    "法下使模型更容易训练。这是由于当sigmoid激活函数输出极接近0或1时，这些区域的梯度⼏乎为0，\r\n",
    "从⽽造成反向传播⽆法继续更新部分模型参数；⽽ReLU激活函数在正区间的梯度恒为1。因此，若模型\r\n",
    "参数初始化不当，sigmoid函数可能在正区间得到⼏乎为0的梯度，从⽽令模型⽆法得到有效训练。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# 实现\r\n",
    "\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "class AlexNet(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(AlexNet,self).__init__()\r\n",
    "        self.conv = nn.Sequential(\r\n",
    "            nn.Conv2d(1,96,11,4), # in_channels,out_channels,kernel_size,stride,padding\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\r\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\r\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(3, 2),\r\n",
    "            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\r\n",
    "            # 前两个卷积层后不使用池化层来减小输入的高和宽\r\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(3, 2)\r\n",
    "        )\r\n",
    "\r\n",
    "        # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合\r\n",
    "        self.fc = nn.Sequential(\r\n",
    "            nn.Linear(256*5*5, 4096),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Dropout(0.5),\r\n",
    "            nn.Linear(4096, 4096),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Dropout(0.5),\r\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\r\n",
    "            nn.Linear(4096, 10),\r\n",
    "        )\r\n",
    "    \r\n",
    "    def forward(self, img):\r\n",
    "        feature = self.conv(img)\r\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\r\n",
    "        return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "net = AlexNet()\r\n",
    "print(net)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AlexNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.6.3 读取数据\r\n",
    "\r\n",
    " 我们仍用前面的Fashion-MNIST数据集来演示AlexNet。读取数据的时候我们额外做了一步将图像高和宽扩大到AlexNet使用的图像高和宽224。这个可以通过`torchvision.transforms.Resize`实例来实现。也就是说，我们在`ToTensor`实例前使用`Resize`实例，然后使用`Compose`实例来将这两个变换串联以方便调用。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None, root='./Datasets/FashionMNIST'):\r\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\r\n",
    "    trans = []\r\n",
    "    if resize:\r\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\r\n",
    "    trans.append(torchvision.transforms.ToTensor())\r\n",
    "    \r\n",
    "    transform = torchvision.transforms.Compose(trans)\r\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\r\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\r\n",
    "\r\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\r\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\r\n",
    "\r\n",
    "    return train_iter, test_iter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "batch_size = 128\r\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\r\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "print(train_iter)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x0000016C8ED123A0>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "### 5.6.4 训练\r\n",
    "\r\n",
    "lr, num_epochs = 0.001, 5\r\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\r\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training on  cpu\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 小结\r\n",
    "\r\n",
    "* AlexNet跟LeNet结构类似，但使用了更多的卷积层和更大的参数空间来拟合大规模数据集ImageNet。它是浅层神经网络和深度神经网络的分界线。\r\n",
    "* 虽然看上去AlexNet的实现比LeNet的实现也就多了几行代码而已，但这个观念上的转变和真正优秀实验结果的产生令学术界付出了很多年。"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.7 使用重复元素的网络（VGG）\r\n",
    "\r\n",
    "AlexNet在LeNet的基础上增加了3个卷积层。但AlexNet作者对它们的卷积窗口、输出通道数和构造顺序均做了大量的调整。虽然AlexNet指明了深度卷积神经网络可以取得出色的结果，但并没有提供简单的规则以指导后来的研究者如何设计新的网络。我们将在本章的后续几节里介绍几种不同的深度网络设计思路。\r\n",
    "\r\n",
    " VGG提出了可以通过重复使用简单的基础块来构建深度模型的思路。\r\n",
    "\r\n",
    "### 5.7.1 VGG块\r\n",
    "\r\n",
    "VGG块的组成规律是：连续使用数个相同的填充为1、窗口形状为$3\\times 3$的卷积层后接上一个步幅为2、窗口形状为$2\\times 2$的最大池化层。卷积层保持输入的高和宽不变，而池化层则对其减半。我们使用`vgg_block`函数来实现这个基础的VGG块，它可以指定卷积层的数量和输入输出通道数。\r\n",
    "\r\n",
    "> 对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核优于采用大的卷积核，因为可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。例如，在VGG中，使用了3个3x3卷积核来代替7x7卷积核，使用了2个3x3卷积核来代替5*5卷积核，这样做的主要目的是在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络效果"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}