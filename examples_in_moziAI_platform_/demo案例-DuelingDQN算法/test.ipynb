{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "import torch\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "BATCH_SIZE = 32\r\n",
    "LR = 0.01\r\n",
    "EPSILON = 0.9\r\n",
    "GAMMA = 0.9\r\n",
    "TARGET_REPLACE_ITER = 100\r\n",
    "MEMORY_CAPACITY = 2000\r\n",
    "EPISODE_NUM = 400\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "\r\n",
    "class duelingdqnNet(nn.Module):\r\n",
    "    def __init__(self, STATE_NUM, ACTION_NUM):\r\n",
    "        super(duelingdqnNet, self).__init__()  # 使用了nn.Modules需要调用super以进行初始化\r\n",
    "\r\n",
    "        self.ACTION_NUM = ACTION_NUM\r\n",
    "\r\n",
    "        self.fc1_a = nn.Linear(in_features=STATE_NUM, out_features=512)  #\r\n",
    "        self.fc1_v = nn.Linear(in_features=STATE_NUM, out_features=512)  #\r\n",
    "\r\n",
    "        self.fc2_a = nn.Linear(in_features=512, out_features=ACTION_NUM)\r\n",
    "        self.fc2_v = nn.Linear(in_features=512, out_features=1)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        a = F.relu(self.fc1_a(x))\r\n",
    "        v = F.relu(self.fc1_v(x))\r\n",
    "\r\n",
    "        a = self.fc2_a(a)\r\n",
    "        v = self.fc2_v(v).expand(x.size(0), self.ACTION_NUM)\r\n",
    "\r\n",
    "        x = a + v - a.mean(1).unsqueeze(1).expand(x.size(0), self.ACTION_NUM)\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "for i in range(2,4):\r\n",
    "    q_next = torch.randn([i,3])\r\n",
    "    # print(\"q_next.shape is \", q_next.shape)\r\n",
    "\r\n",
    "    q_eval = torch.randn([i,3])\r\n",
    "    print(\"q_eval.shape is \", q_eval.shape)\r\n",
    "\r\n",
    "    batch_reward = torch.randn(q_eval.shape)\r\n",
    "    print(\"batch_reward.shape is \", batch_reward.shape)\r\n",
    "\r\n",
    "    q_target = batch_reward + GAMMA * q_next.max(1)[0].view(-1,1)  # 使用target_net来推荐最大reward值\r\n",
    "    print(\"q_target.shape is \",q_target.shape)\r\n",
    "\r\n",
    "    print(q_target.shape == q_eval.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "q_eval.shape is  torch.Size([2, 3])\n",
      "batch_reward.shape is  torch.Size([2, 3])\n",
      "q_target.shape is  torch.Size([2, 3])\n",
      "True\n",
      "q_eval.shape is  torch.Size([3, 3])\n",
      "batch_reward.shape is  torch.Size([3, 3])\n",
      "q_target.shape is  torch.Size([3, 3])\n",
      "True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}