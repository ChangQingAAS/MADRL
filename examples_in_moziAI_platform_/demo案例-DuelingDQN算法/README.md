# 代码简介

Agent表示：
  - 经度
  - 维度
  - 朝向

4 agents(红色):
  - 结伴飞行

trainer: 
  - Dueling DQN算法

4障碍物(蓝色)： 
  - 分布在不同区域
  - 静态

任务描述：
  - agents从起点飞到目的点
  - 不碰撞障碍物


## 设计方式：

  - agents的奖惩函数，
    - 主线reward：  有多么靠近目的点；
    - 辅助reward：  有多么远离障碍物

  - 是否done:
    - 离目标位置太远了
    - 碰到障碍物
    - 到达目标位置（实际上是按照非常接近目的地来训练的

  - 执行动作：
    - 改变朝向
    - 前进速度

  训练过程：
    - 输入动作
    - 执行动作
    - 更新态势
    - 获取观察
    - 检查是否结束


改进方向：
  - 目前是一个方形轮子的汽车,输出的动作不对劲
  - 基本结构和接口都完成了
  - 一些网络参数需要调整
  - 不知道能不能达到DDPG算法那样好的效果
  - 这次，把所有能用的封装出来，尽量让以后嵌入算法更方便
  - 因为这次不是调用现成的算法，自己添加新的算法，需要调整一些东西，而且网络参数还要自己整一下

TODO:
  - 解决在文件里标识的TODO
  - 运行代码，打印出相应参数的类型，根据这些类型修改网络里的参数（网络虽然搭起来了，但是有东西没对上
  - 修改对loss的显示
  - 写入 导入model