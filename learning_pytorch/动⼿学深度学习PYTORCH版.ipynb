{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e4a29ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a94a58",
   "metadata": {},
   "source": [
    "## 2.2 数据操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37237c",
   "metadata": {},
   "source": [
    "### 2.2.1创建 `tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bf6e338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9184e-39, 8.7245e-39, 9.2755e-39],\n",
       "        [8.9082e-39, 9.9184e-39, 8.4490e-39],\n",
       "        [9.6429e-39, 1.0653e-38, 1.0469e-38],\n",
       "        [4.2246e-39, 1.0378e-38, 9.6429e-39],\n",
       "        [9.2755e-39, 9.7346e-39, 1.0745e-38]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建⼀个5x3的未初始化的 Tensor\n",
    "x = torch.empty(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02a0e6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4496, 0.0336, 0.3475],\n",
       "        [0.5923, 0.2153, 0.8279],\n",
       "        [0.4446, 0.3286, 0.7065],\n",
       "        [0.7721, 0.6562, 0.4355],\n",
       "        [0.2791, 0.8337, 0.1916]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建⼀个5x3的随机初始化的 Tensor :\n",
    "x = torch.rand(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a1d4b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建⼀个5x3的long型全0的 Tensor :\n",
    "x = torch.zeros(5,3,dtype = torch.long)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44fb67e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000, 2.0000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接创建\n",
    "x = torch.tensor([5.5,2])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31976ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过现有的tensor插件，会默认重用输入tensor的一些属性，如数据类型等，除非自定义数据类型\n",
    "x = x.new_ones(5, 3, dtype = torch.float64)\n",
    "# 返回的tensor默认具有相同的torch.dtype和torch.device\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7471841b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.8216e-02, -7.3244e-01, -7.2631e-01],\n",
       "        [ 2.2480e+00,  4.3884e-01, -3.3377e-01],\n",
       "        [ 1.9736e+00,  7.4171e-01,  2.4990e-01],\n",
       "        [ 6.7954e-01, -1.7059e+00,  1.8729e-01],\n",
       "        [ 3.0848e-01,  2.1080e-03,  1.2143e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 制定新的数据类型\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57ff4edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]), torch.Size([5, 3]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以通过哦shape,size()来获取tensor的形状\n",
    "x.size(),x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb5387",
   "metadata": {},
   "source": [
    "> 注意：返回的torch.Size其实就是一个tuple, 支持所有tuple的操作。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e202a9cc",
   "metadata": {},
   "source": [
    "还有很多函数可以创建`Tensor`，去翻翻官方API就知道了，下表给了一些常用的作参考。\n",
    "\n",
    "|函数|功能|\n",
    "|:---:|:---:|\n",
    "|Tensor(*sizes)|基础构造函数|\n",
    "|tensor(data,)|类似np.array的构造函数|\n",
    "|ones(*sizes)|全1Tensor|\n",
    "|zeros(*sizes)|全0Tensor|\n",
    "|eye(*sizes)|对角线为1，其他为0|\n",
    "|arange(s,e,step)|从s到e，步长为step|\n",
    "|linspace(s,e,steps)|从s到e，均匀切分成steps份|\n",
    "|rand/randn(*sizes)|均匀/标准分布|\n",
    "|normal(mean,std)/uniform(from,to)|正态分布/均匀分布|\n",
    "|randperm(m)|随机排列|\n",
    "\n",
    "这些创建方法都可以在创建的时候指定数据类型dtype和存放device(cpu/gpu)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b936d0a",
   "metadata": {},
   "source": [
    "## 2.2.2 操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6722fa35",
   "metadata": {},
   "source": [
    "### 加法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49debfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0719,  0.2269, -0.7175],\n",
      "        [ 2.5992,  0.6161, -0.2806],\n",
      "        [ 2.2163,  1.0230,  0.2533],\n",
      "        [ 1.0392, -1.0469,  0.3603],\n",
      "        [ 1.0761,  0.2050,  1.5645]])\n",
      "tensor([[ 0.0719,  0.2269, -0.7175],\n",
      "        [ 2.5992,  0.6161, -0.2806],\n",
      "        [ 2.2163,  1.0230,  0.2533],\n",
      "        [ 1.0392, -1.0469,  0.3603],\n",
      "        [ 1.0761,  0.2050,  1.5645]])\n",
      "tensor([[ 0.0719,  0.2269, -0.7175],\n",
      "        [ 2.5992,  0.6161, -0.2806],\n",
      "        [ 2.2163,  1.0230,  0.2533],\n",
      "        [ 1.0392, -1.0469,  0.3603],\n",
      "        [ 1.0761,  0.2050,  1.5645]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0719,  0.2269, -0.7175],\n",
       "        [ 2.5992,  0.6161, -0.2806],\n",
       "        [ 2.2163,  1.0230,  0.2533],\n",
       "        [ 1.0392, -1.0469,  0.3603],\n",
       "        [ 1.0761,  0.2050,  1.5645]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "y = torch.rand(5,3)\n",
    "\n",
    "# 加法形式1：\n",
    "print(x + y )\n",
    "\n",
    "# 加法形式2：\n",
    "print(torch.add(x,y))\n",
    "#还可以指定输出\n",
    "res = torch.empty(5,3)\n",
    "torch.add(x,y,out=res)\n",
    "print(res)\n",
    "\n",
    "# 加法形式3：\n",
    "y.add_(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ad10f9",
   "metadata": {},
   "source": [
    "### 索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91cd59dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.0582, 1.2676, 1.2737]), tensor([2.0582, 1.2676, 1.2737]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 索引出来的结果与原数据共享内存，也即修改⼀个，另⼀个会跟着修改\n",
    "y = x[0,:]\n",
    "y += 1\n",
    "\n",
    "y,x[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8de9b73",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-a7743ddc4e52>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-31-a7743ddc4e52>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    y = torch.index_select(x,1,2,*,y)\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "y = torch.index_select(x,1,2,*,y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc57231",
   "metadata": {},
   "source": [
    "除了常用的索引选择数据之外，PyTorch还提供了一些高级的选择函数:\n",
    "\n",
    "|函数|\t功能|\n",
    "|:---:|:---:|\n",
    "|index_select(input, dim, index)|在指定维度dim上选取，比如选取某些行、某些列|\n",
    "|masked_select(input, mask)|例子如上，a[a>0]，使用ByteTensor进行选取|\n",
    "|nonzero(input)|\t非0元素的下标|\n",
    "|gather(input, dim, index)|根据index，在dim维度上选取数据，输出的size与index一样|\n",
    "\n",
    "这里不详细介绍，用到了再查官方文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794298bc",
   "metadata": {},
   "source": [
    "### 改变形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12435434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]), torch.Size([15]), torch.Size([3, 5]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view()返回的新tensor与源tensor共享内存\n",
    "# view仅改变了观察方式\n",
    "y = x.view(15)\n",
    "z = x.view(-1,5)\n",
    "\n",
    "x.size(),y.size(),z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db215a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0582, 3.2676, 3.2737],\n",
      "        [4.2480, 2.4388, 1.6662],\n",
      "        [3.9736, 2.7417, 2.2499],\n",
      "        [2.6795, 0.2941, 2.1873],\n",
      "        [2.3085, 2.0021, 3.2143]])\n",
      "tensor([4.0582, 3.2676, 3.2737, 4.2480, 2.4388, 1.6662, 3.9736, 2.7417, 2.2499,\n",
      "        2.6795, 0.2941, 2.1873, 2.3085, 2.0021, 3.2143])\n"
     ]
    }
   ],
   "source": [
    "x += 1\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a6361d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.0582,  2.2676,  2.2737],\n",
      "        [ 3.2480,  1.4388,  0.6662],\n",
      "        [ 2.9736,  1.7417,  1.2499],\n",
      "        [ 1.6795, -0.7059,  1.1873],\n",
      "        [ 1.3085,  1.0021,  2.2143]])\n",
      "tensor([4.0582, 3.2676, 3.2737, 4.2480, 2.4388, 1.6662, 3.9736, 2.7417, 2.2499,\n",
      "        2.6795, 0.2941, 2.1873, 2.3085, 2.0021, 3.2143])\n"
     ]
    }
   ],
   "source": [
    "# 如果我们想返回⼀个真正新的副本（即不共享内存）\n",
    "#Pytorch还提供了⼀个 reshape() 可以改变形状，但是此函数并不能保证返回的是其拷⻉，所以不推荐使⽤\n",
    "# 推荐先⽤ clone 创造⼀个副本然后再使⽤ view\n",
    "\n",
    "x_cp = x.clone().view(15)\n",
    "x -= 1\n",
    "\n",
    "print(x)\n",
    "print(x_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd71c421",
   "metadata": {},
   "source": [
    "> 使用`clone`还有一个好处是会被记录在计算图中，即梯度回传到副本时也会传到源`Tensor`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6876d6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.4378]), -0.4377901256084442)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# item()将一个标量tensor转变成numpy\n",
    "# only one element tensors can be converted to Python scalars\n",
    "x = torch.randn(1)\n",
    "x,x.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2ac529",
   "metadata": {},
   "source": [
    "### 线性代数\n",
    "另外，PyTorch还支持一些线性函数，这里提一下，免得用起来的时候自己造轮子，具体用法参考官方文档。如下表所示：\n",
    "\n",
    "| 函数\t|功能|\n",
    "|:---:|:---:|\n",
    "|trace|\t对角线元素之和(矩阵的迹)|\n",
    "|diag|\t对角线元素|\n",
    "|triu/tril\t|矩阵的上三角/下三角，可指定偏移量|\n",
    "|mm/bmm\t|矩阵乘法，batch的矩阵乘法|\n",
    "|addmm/addbmm/addmv/addr/baddbmm..|\t矩阵运算|\n",
    "|t|转置|\n",
    "|dot/cross|\t内积/外积|\n",
    "|inverse\t|求逆矩阵|\n",
    "|svd\t|奇异值分解|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe93d3",
   "metadata": {},
   "source": [
    "## 2.2.3 广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff9ed70",
   "metadata": {},
   "source": [
    "前面我们看到如何对两个形状相同的`Tensor`做按元素运算。\n",
    "\n",
    "当对两个形状不同的`Tensor`按元素运算时，可能会触发广播（broadcasting）机制：\n",
    "\n",
    "先适当复制元素使这两个`Tensor`形状相同后再按元素运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78e2c5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1],\n",
       "         [2]]),\n",
       " tensor([[1, 2, 3, 4]]),\n",
       " tensor([[2, 3, 4, 5],\n",
       "         [3, 4, 5, 6]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 3).view(1, 2)\n",
    "print(x)\n",
    "y = torch.arange(1, 4).view(3, 1)\n",
    "print(y)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de30882",
   "metadata": {},
   "source": [
    "由于 x 和 y 分别是1⾏2列和3⾏1列的矩阵，如果要计算 x + y ，那么 x 中第⼀⾏的2个元素被⼴播\n",
    "（复制）到了第⼆⾏和第三⾏，⽽ y 中第⼀列的3个元素被⼴播（复制）到了第⼆列。如此，就可以对2\n",
    "个3⾏2列的矩阵按元素相加"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad2703",
   "metadata": {},
   "source": [
    "### 2.2.4运算的内存开销"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb386a",
   "metadata": {},
   "source": [
    "前⾯说了，索引、 view 是不会开辟新内存的，⽽像 y = x + y 这样的运算是会新开内存的，然后将 y 指向新内存为了演示这⼀点，我们可以使⽤Python⾃带的 id 函数：如果两个实例的ID⼀致，那么它们所对应的内存地址相同；反之则不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f5e7e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2629405413312, 2629405490496, -77184)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "y_id = id(y)\n",
    "y = y + x\n",
    "y_id_ = id(y)\n",
    "\n",
    "y_id,y_id_,y_id - y_id_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab51f0d",
   "metadata": {},
   "source": [
    "如果想指定结果到原来的 y 的内存，我们可以使⽤前⾯介绍的索引来进⾏替换操作。在下⾯的例⼦中，我们把 x + y 的结果通过 [:] 写进 y 对应的内存中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ff62d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2629405488448, 2629405488448, 0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "y_id = id(y)\n",
    "y[:] = y + x\n",
    "y_id_ = id(y)\n",
    "\n",
    "y_id,y_id_,y_id - y_id_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32493564",
   "metadata": {},
   "source": [
    "我们还可以使⽤运算符全名函数中的 out 参数或者⾃加运算符 += (也即 add_() )达到上述效果，例如\n",
    "torch.add(x, y, out=y) 和 y += x ( y.add_(x) )。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3407c10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2629405519360, 2629405519360, True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2])\n",
    "y = torch.tensor([3, 4])\n",
    "y_id = id(y)\n",
    "torch.add(x,y,out=y)# or y += x, y.add_(x)\n",
    "y_id_ = id(y)\n",
    "\n",
    "y_id,y_id_,y_id == y_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf13a2a",
   "metadata": {},
   "source": [
    "### 2.2.5 TENSOR 和NUMPY相互转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750bf1b",
   "metadata": {},
   "source": [
    "Notes: tensor和numpy中的数组也共享内存,（所以他们之间的转换很\n",
    "快），改变其中⼀个时另⼀个也会改变！！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8992c286",
   "metadata": {},
   "source": [
    "#### numpy中的array转换成tensor\n",
    "需要注意的是，此⽅法总是会进⾏数据拷⻉（就会消耗更多的时间和空间），所以返回的 Tensor 和原来的数\n",
    "据不再共享内存。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa25877c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 2., 2.]), tensor([2., 2., 2.], dtype=torch.float64))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones(3)\n",
    "b = torch.from_numpy(a)\n",
    "\n",
    "a += 1\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f7d42d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 2., 2.]), tensor([2., 2., 2.], dtype=torch.float64))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 法2\n",
    "b = torch.tensor(a)\n",
    "\n",
    "a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee3db96",
   "metadata": {},
   "source": [
    "所有在CPU上的 Tensor （除了 CharTensor ）都⽀持与NumPy数组相互转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d4777",
   "metadata": {},
   "source": [
    "#### tensor转numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b15a0e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2.]), array([2., 2.], dtype=float32))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(2)\n",
    "b = a.numpy()\n",
    "\n",
    "a += 1\n",
    "\n",
    "a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd247f85",
   "metadata": {},
   "source": [
    "### 2.2.6 TENSOR ON GPU\n",
    "用方法`to()`可以将`Tensor`在CPU和GPU（需要硬件支持）之间相互移动。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "203cdd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下代码只有在PyTorch GPU版本上才会执行\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # GPU\n",
    "    y = torch.ones_like(x, device=device)  # 直接创建一个在GPU上的Tensor\n",
    "    x = x.to(device)                       # 等价于 .to(\"cuda\")\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # to()还可以同时更改数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bfea30",
   "metadata": {},
   "source": [
    "## 2.3 ⾃动求梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad58f0a",
   "metadata": {},
   "source": [
    "在深度学习中，我们经常需要对函数求梯度（gradient）。PyTorch提供的autograd 包能够根据输⼊\n",
    "和前向传播过程⾃动构建计算图，并执⾏反向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcf9814",
   "metadata": {},
   "source": [
    "### 2.3.1 概念"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5075729",
   "metadata": {},
   "source": [
    "上一节介绍的`Tensor`是这个包的核心类，如果将其属性`.requires_grad`设置为`True`，它将开始追踪(track)在其上的所有操作（这样就可以利用链式法则进行梯度传播了）。完成计算后，可以调用`.backward()`来完成所有梯度计算。此`Tensor`的梯度将累积到`.grad`属性中。\n",
    "> 注意在`y.backward()`时，如果`y`是标量，则不需要为`backward()`传入任何参数；否则，需要传入一个与`y`同形的`Tensor`。解释见 2.3.2 节。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05eee76",
   "metadata": {},
   "source": [
    "如果不想要被继续追踪，可以调⽤ .detach() 将其从追踪记录中分离出来，这样就可以防⽌将来的计算被追踪，这样梯度就传不过去了。此外，还可以⽤ with torch.no_grad() 将不想被追踪的操作代码块包裹起来，这种⽅法在评估模型的时候很常⽤，因为在评估模型时，我们并不需要计算可训练参数（ requires_grad=True ）的梯度。\n",
    "\n",
    "Function 是另外⼀个很᯿要的类。 Tensor 和 Function 互相结合就可以构建⼀个记录有整个计算过程的有向⽆环图（DAG）。每个 Tensor 都有⼀个 .grad_fn 属性，该属性即创建该 Tensor 的Function , 就是说该 Tensor 是不是通过某些运算得到的，若是，则 grad_fn 返回⼀个与这些运算相关的对象，否则是None。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d9a5b",
   "metadata": {},
   "source": [
    "## 2.3.2 `Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d987022c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.]], requires_grad=True),\n",
       " None)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 即把x当做变量\n",
    "x = torch.ones(2,2,requires_grad = True)\n",
    "x,x.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "32e8274c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 3.],\n",
       "         [3., 3.]], grad_fn=<AddBackward0>),\n",
       " <AddBackward0 at 0x26434c83be0>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 做一下运算\n",
    "\n",
    "y = x +2\n",
    "y,y.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66607b52",
   "metadata": {},
   "source": [
    "注意x是直接创建的，所以它没有 grad_fn , ⽽y是通过⼀个加法操作创建的，所以它有⼀个为\n",
    "<AddBackward> 的 grad_fn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fc319f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "# 像x这种直接创建的称为叶⼦节点，叶⼦节点对应的 grad_fn 是 None 。\n",
    "print(x.is_leaf,y.is_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3e47fcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "<MulBackward0 object at 0x0000026434C7FA90>\n",
      "\n",
      "tensor(27., grad_fn=<MeanBackward0>)\n",
      "<MeanBackward0 object at 0x0000026434C882B0>\n"
     ]
    }
   ],
   "source": [
    "# 可以从grad_fn看出本次的操作 or 运算\n",
    "z = y ** 2 * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z)\n",
    "print(z.grad_fn)\n",
    "print()\n",
    "print(out)\n",
    "print(out.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88cbc7a",
   "metadata": {},
   "source": [
    "通过`.requires_grad_()`来用in-place的方式改变`requires_grad`属性：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "63700e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x0000026433C527C0>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2) # 缺失情况下默认 requires_grad = False\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad) # False\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad) # True\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f6c95",
   "metadata": {},
   "source": [
    "## 2.3.3 梯度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8d6fcfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  因为 out 是⼀个标量，所以调⽤ backward() 时不需要指定求导变量\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae0b76",
   "metadata": {},
   "source": [
    " 我们来看看`out`关于`x`的梯度 $\\frac{d(out)}{dx}$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f5233398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642b7b56",
   "metadata": {},
   "source": [
    "我们令`out`为 $o$ , 因为\n",
    "$$\n",
    "o=\\frac14\\sum_{i=1}^4z_i=\\frac14\\sum_{i=1}^43(x_i+2)^2\n",
    "$$\n",
    "所以\n",
    "$$\n",
    "\\frac{\\partial{o}}{\\partial{x_i}}\\bigr\\rvert_{x_i=1}=\\frac{9}{2}=4.5\n",
    "$$\n",
    "所以上面的输出是正确的。\n",
    "\n",
    "数学上，如果有一个函数值和自变量都为向量的函数 $\\vec{y}=f(\\vec{x})$, 那么 $\\vec{y}$ 关于 $\\vec{x}$ 的梯度就是一个雅可比矩阵（Jacobian matrix）:\n",
    "$$\n",
    "J=\\left(\\begin{array}{ccc}\n",
    "   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
    "   \\vdots & \\ddots & \\vdots\\\\\n",
    "   \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    "   \\end{array}\\right)\n",
    "$$\n",
    "而``torch.autograd``这个包就是用来计算一些雅克比矩阵的乘积的。例如，如果 $v$ 是一个标量函数的 $l=g\\left(\\vec{y}\\right)$ 的梯度：\n",
    "$$\n",
    "v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)\n",
    "$$\n",
    "那么根据链式法则我们有 $l$ 关于 $\\vec{x}$ 的雅克比矩阵就为:\n",
    "$$\n",
    "v J=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right) \\left(\\begin{array}{ccc}\n",
    "   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
    "   \\vdots & \\ddots & \\vdots\\\\\n",
    "   \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    "   \\end{array}\\right)=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial x_{1}} & \\cdots & \\frac{\\partial l}{\\partial x_{n}}\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "注意：grad在反向传播过程中是累加的(accumulated)，这意味着每一次运行反向传播，梯度都会累加之前的梯度，所以一般在反向传播之前需把梯度清零。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7b9416f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#再来一次反向传播，注意grad是累加的\n",
    "\n",
    "out2 = x.sum()\n",
    "out2.backward()\n",
    "print(x.grad)\n",
    "\n",
    "out3 = x.sum()\n",
    "x.grad.data.zero_()\n",
    "out3.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b880d3be",
   "metadata": {},
   "source": [
    "\n",
    "> 现在我们解释2.3.1节留下的问题，为什么在`y.backward()`时，如果`y`是标量，则不需要为`backward()`传入任何参数；否则，需要传入一个与`y`同形的`Tensor`?\n",
    "简单来说就是为了避免向量（甚至更高维张量）对张量求导，而转换成标量对张量求导。举个例子，假设形状为 `m x n` 的矩阵 X 经过运算得到了 `p x q` 的矩阵 Y，Y 又经过运算得到了 `s x t` 的矩阵 Z。那么按照前面讲的规则，dZ/dY 应该是一个 `s x t x p x q` 四维张量，dY/dX 是一个 `p x q x m x n`的四维张量。问题来了，怎样反向传播？怎样将两个四维张量相乘？？？这要怎么乘？？？就算能解决两个四维张量怎么乘的问题，四维和三维的张量又怎么乘？导数的导数又怎么求，这一连串的问题，感觉要疯掉…… \n",
    "为了避免这个问题，我们**不允许张量对张量求导，只允许标量对张量求导，求导结果是和自变量同形的张量**。所以必要时我们要**把张量通过将所有张量的元素加权求和的方式转换为标量**，举个例子，假设`y`由自变量`x`计算而来，`w`是和`y`同形的张量，则`y.backward(w)`的含义是：先计算`l = torch.sum(y * w)`，则`l`是个标量，然后求`l`对自变量`x`的导数。\n",
    "[参考](https://zhuanlan.zhihu.com/p/29923090)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9dd334ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [6., 8.]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only Tensors of floating point and complex dtype can require gradients\n",
    "x = torch.tensor([1.,2.,3.,4.],requires_grad=True)\n",
    "y = 2 * x\n",
    "z = y.view(2,2)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf41dd8c",
   "metadata": {},
   "source": [
    "现在 z 不是⼀个标量，所以在调⽤ backward 时需要传⼊⼀个和z同形的权重向量进⾏加权求和得到\n",
    "⼀个标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a213de6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 0.2000, 0.0200, 0.0020])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([[1.0, 0.1], [0.01, 0.001]], dtype=torch.float)\n",
    "z.backward(v)\n",
    "print(x.grad)\n",
    "# 注意， x.grad 是和 x 同形的张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d35d98",
   "metadata": {},
   "source": [
    "**为什么**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2eed9fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for question\n",
    "l = torch.sum(v * z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "42386017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor(1., grad_fn=<PowBackward0>) True\n",
      "tensor(1.) False\n",
      "tensor(2., grad_fn=<AddBackward0>) True\n",
      "tensor(2.)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-575a1166fcfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 只算了y1 part\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0my2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# 再来卡看中断梯度的例子：\n",
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "y1 = x ** 2\n",
    "with torch.no_grad():\n",
    "    y2 = x ** 3\n",
    "y3 = y1 + y2\n",
    "\n",
    "print(x.requires_grad)\n",
    "print(y1, y1.requires_grad)\n",
    "print(y2, y2.requires_grad)\n",
    "print(y3, y3.requires_grad)\n",
    "\n",
    "y3.backward()\n",
    "print(x.grad) # 只算了y1 part\n",
    "\n",
    "y2.backward() # 因为requires_grad = false，所以报错"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb8a8f",
   "metadata": {},
   "source": [
    "此外，如果我们想要修改 tensor 的数值，但是⼜不希望被 autograd 记录（即不会影响反向传播），\n",
    "那么我么可以对 tensor.data 进⾏操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8abc8437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "False\n",
      "tensor([100.], requires_grad=True)\n",
      "tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(1,requires_grad=True)\n",
    "print(x.data) # 还是⼀个tensor\n",
    "print(x.data.requires_grad) # 但是已经是独⽴于计算图之外\n",
    "y = 2 * x\n",
    "x.data *= 100 # 只改变了值，不会记录在计算图，所以不会影响梯度传播\n",
    "y.backward()\n",
    "print(x) # 更改data的值也会影响tensor的值\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1328e7",
   "metadata": {},
   "source": [
    "## 3.1 线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86545eb5",
   "metadata": {},
   "source": [
    "线性回归输出是⼀个连续值，因此适⽤于回归问题。回归问题在实际中很常⻅，如预测房屋价格、⽓\n",
    "温、销售额等连续值的问题。与回归问题不同，分类问题中模型的最终输出是⼀个离散值。我们所说的\n",
    "图像分类、垃圾邮件识别、疾病检测等输出为离散值的问题都属于分类问题的范畴。softmax回归则适\n",
    "⽤于分类问题。\n",
    "由于线性回归和softmax回归都是单层神经⽹络，它们涉及的概念和技术同样适⽤于⼤多数的深度学习\n",
    "模型。我们⾸先以线性回归为例，介绍⼤多数深度学习模型的基本要素和表示⽅法。"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADKCAYAAAC11LviAAAgAElEQVR4Ae19d1xUx/d2YtTEmKYxzXRTjDEdWGBREBUFFSUKimJDFBQ7KvaCEsUSGyoqih0VNYoKlmAvWGMhomLFgiLBgkj78nuf93Puci93K7uwnfnjfu7ubTNz5pxnzpw5c85LxcXFYAejAeMBxgOMByyfB15inWj5ncj6kPUh4wHGA8QDDNDZDIXN0BgPMB6wEh5ggG4lHck0NKahMR5gPMAAnQE6084YDzAesBIeYIBuJR3JtDOmnYl5oKioCKmpqYiNjcWIESPQp08flcfEiROxdetWpKen43//+x8DdgvHAwboFt6BYiFmvysvqOfn52Pz5s0YMGAAnJycULNmTbz00ks6HXXq1IGbmxtCQ0Nx8OBBBvAWiA0M0C2w0xhwV17gVuz7mzdvYuzYsfjwww/Vgnf1N2qh1hcNUeuLH+SOdz7/Hq9Ur6H2ve+//x7z5s1DdnY209wtBCcYoFtIRykKMvtfeUGdzCnx8fFo3bo1Xn75ZTlAfu3t9/CZQ2v82nUc3Cb/hc7rb6PP/v+HwANQefRO+h98VlyC65i1+NEnBHV/cUXV196Q+2aNGjXQs2dPnDhxggG7meMFA3Qz7yAG3JUXuFX1/eXLlzmTipw55eUq+MyhDdyn7kTvpGKVwK0O0FVd77XrBVxGrsD7DezlgJ3K7Nq1K7KyshiwmyluMEA3045RJczsWuUF98LCQsyYMQOvvvqqALKv1/4Iv3Ubjy4b0isM4qqAna61X/oPGngGoeprpTb5Dz74AFu2bGGgbobYwQDdDDuFAXflBW5VfZ+SkgJ7+1JtuUrV6rDrPRW9/y4yGJArAnyP7Y9R36OXMJiQtt6pUyc8fPiQAbsZYQgDdDPqDFXCzK5VbnBfsGABqlevLgApmUHI5q0IuMb67zF9F2q+96lQn/feew9///03A3UzwREG6GbSEQy4KzdwK/Y/+YSTjzhvK3+l2muw7ztTLzbyioJ/z53PODMMXzcacJgJxjz4lwE6A3SmXZkZDxCYDxkyRADzt+p+hY6rrphMK1c3AHhM3y3nEdOtWzfGSybmJQboJu4ARc2M/TcPTceU/cAAnfFAefmPAToDdKZVmRkPjBo1StDOa3/5I7puzjA77ZzX2r2iTgl1JRNMXFwc4ycT8hMDdBMSv7yjMHvPejW46dOnCwBZ55vf0D0+22zBnAf1VjP3CnWuVq0adu/ezUDdRLjCAN1EhGegbL2gXN6+3bFjhwCM73z6HbptfWT2YM6DevslZ1Ht9be4+lMcmRs3bjBQNwG2MEA3AdHLK/DsPesdBCheSt26dTlApA1DXTbesRgw50Hdc+4hvFylKteG5s2bs+BeJsAWBugmIDoDZusF5vL2ba9epZt2Wk7dYXFgzoM6xZDh3RmXLFnCtHQj4wsDdCMTvLwCz96z3kEgMTFRAMGvm3e1WDAnUA/YU8BFdiRQf/PNN3Hr1i0G6kbEGAboRiQ2A2XrBeXy9u2TJ0/w6aeynZc1an1gEYugvDau7sx5vrxchRukWrZsyUwvRsQYBuhGJHZ5hZ69Z70DwdChQwXtnMLdqgNJS7v+c+eRQrvWr1/PtHQj4QwDdCMRmoGy9YJyefv2/v37qFpVtoj4Q/tBVgPmNPhQDPb3GzhwoP7tt98yLd1IOMMA3UiELq/Qs/esdyD4448/BC3WHLf2V3RW4DpmjdC+pKQkpqUbAWsYoBuByAyUrReUy9u3lHXo888/5wCv7q9NrUo75weCXnvy8eqbtbk2+vj4MEA3AtYwQDcCkcsr9Ow96x0Idu7cKWivzSfGWSWgE7D/1HEY104yLZGJifG0YXmaAToDdCZkJuCBdu3acUBHni0BewutFtA7rr4qDFxkYmKAbmaAvnHjRixdurTMjiENZPLkycjLyyvzWU2dvHnzZgQGBiI3N7dC39FUBrtnWCZj9JWnb35+vpC0grxBeBOFtZ4/+rkJB+oODg5Mhg2sPOisobu5uaFRo0YaO+bQoUMcw1JG8orGSB4xYgTHDLQ1WldgWLZsGVq0aFHu4+jRozqXqWsd2fPyYFcZ6PHPP/8IWqt7RKLVA/pvPWSJOmrUqAHKjVoZ+thUbdQZ0N955x0MGzZMbaccP34c9EyHDh24LCYE6pqep4afPHkStWrVQmxsrNJ3NQE65Vls27at0js8MUNDQznBady4MXQ5fv31V+49loWl8oEtzzuGPC9fvlwA9K5bHlo9oLeYsk1o77///qtWXg1J88ryba0A/dKlSyBwHDBgANcxHh4e3H+6RgefKHb//v144403YGtri5ycHK7jZs6cyb0THBys1heVNGHaKrxixQqlztYE6PXr14eLi4vSO3znUd2qVKmi9j7/nOL5xIkTXH0YoDNAV+QNffzv378/x18UhMtazSzidlGgMT6+y9q1a3WWR33QvLJ8QytAj4+PFzqE7xjxmQD/ypUr+Oyzz1CnTh1cuHBB6DSaYnXu3Jl7f+HChcJ1MYEZoDPgFPODtf8mMyDJD9mWxcBnjN9dtzxAmzkH0Gb2fnTf9p9Ryu+dVIyqr77OtXncuHEqMcDa+9xY7dMK0J89ewaaKpEvab169bjf9J8/EhIS8P7773NHnz59MGfOHLnjzz//BIXTJCYmrVnRjmZIQKcyiYl0OQICAri6Mg2dDTT6FkRKL0dKD/Hlj95DjQKoNFD4rLiEeq6dhPC2VH6VqtXxjVs3UNJnQw8mHzSUcm1u06YNA3QDLoxqBeg8U3/zzTfo168fbt68iW3btoE2R1y7do0za9D2XvrdoEEDfPXVV0rH4cOHMXz4cK5T16xZI9ephgb0jz76COU5KAoe33Z2ZuCuDx6gxX0CUzqchy8zOJASUHdYdgHVa76Dl16ugu+9+oPilreasQef2LXk6kEzBdqqb0hQ/65NIFcW4YQ+6Mi+oVoetQZ0ykBCTEhAHhUVxf1+/vw51znz58/Hf//9p1VHHThwQMmWbkhAL48NnTGLamZhdKk4XUhOeECnrfGGBFH6tn9iLt744AuuzGYTNsqV1zvpf3i/gT13r92C43L39F2vhr8P5MohpZDxUcX5SB0NtQb0SZMmcd4r5FeuCOj08cWLF4Ns5OJDEeSbNGkC8mNXrAwP6F9++SXs7Ozkjg8//JBjhN9++03uOj336quvlrko+sorrwjlkf/vixcvtD4U68n+G44RKwttjQ3ormPWcvLzbcseKgG70ZBF3P1fOo9SeV9fwM4A3TiyoxWgExCSycLX1xcZGRmYMWMGxwRkeqH/JIy0tbd27dpcbGd6lrSQlJQUzJo1C4MHD+aeIQ+YyMhIAWB5ISZbPNnYVR18vAsaDFTd1+QSOWjQILz++utCeTQI8NqRNmeyd/J1ZGfjMKS109nYgP6JnTvH878vPqMSsFtM2crd/75tP5X3GaBbFt9rBejkgsiH+VQFhPz96OhoDgAJyHlAJzDnF0LUAbomIdbktqjpPbpHC7TvvvuuAMqUhJdcI7U9yvo+u29ZzG4O/WVMQKfsQS9XeQXVaryJPvv+TyVgNw5ZwsnqL11Gq7zPAN2yeFwrQCdBINs5LWbS4e/vzzFBTEwM95+8VgjwywPoxOAHDx7Eo0ePBOAVC15ZgE677s6cOaPy3a5du+Ljjz9WeU9cBvttWUxryf1lTEDvtvURJ6dvf1pfLVjXc/HhnjF0cg1mcjGOjGkN6GIhUmVDJ0Ane3X16tVRrVo1jklIUy9LQyeXR9Lm1bkIlgXoEokEv/zyi0rQpp2kjo6OnHvllClTUJ4jOTlZ5bfF9GC/jcOs1kBnms3ys1zpwPlqgVYfmnGP7Y+5smrW+URlOV03Z+CVaq/hleo1QM/qo0x136BcqdTuH3/8kcmTubgt8gIlBnTaJUoLpQTo5GNOXiyrVq3iOs+UgE51okXTgQMHIi4uDhRHQnzQ4EMMJr6m6ve8efMYAxqQAXmeqkxn2stBvFe/VYBBQZTMLK/X+ZgryzvmX7my6N6Xzh24ez/6hMjdUwfKFble64sfuLK6dOnC5MmA8qSThk4bjEhj7dWrF9c55HNOjEmLo+U1uRhKQ6d6Ut1Wr16txEBPnz7lFm8p0JgYSGgR9M6dO3LXxPfZb6aJ64MHvL29Od6s881vBgdS6aBIrqzaX/6ItvOPovffRei46jK+aNyeu04bfigRRUXAuqx3e+16wfnAkzySk4Q+aMi+oVoWtQJ0cjWkxUXqEPFBO0fJXZFcAQnQyfRBcZ6bNWvGPWdKDZ00a6pramqqEgNRXBlaoKWBSMwYo0aN4tpJoQzE19lv1czD6FI+uvCp56q8Us3gsdBJEycN/KWXXpaTXZIN2iXaY8cTg4I5gb3XQllsJCqTpaIrH89oK2taATplGqGQuFlZWRzQiU0ufEEE6NOmTUNaWhp27dolAPq6deu4MAD0nCovF0Np6OTiaGNjIwfMpIF7eXnh7bffxsWLF+Xu8e0ICSHmf4lb7OWvsbNhmbCy0ffUqVMCuLaa9bfBAZXXoElTJrs5nflrxjjb9grn2ksm0IKCApVyV9l4wFDt1QrQFQtXB+iqvFzE72oCdPJImTp1qtJB0RQJYCdMmKB0j57/5JNPlBZFyWOmZs2a3Dvi8ilsKYXzVYzqePfuXc7Thq4PHTqUK49mJLdv32bMZ0B7n7hvKtPvJ0+eCIDuEDzbqOBqDABXLINiyJAMN2zYkMmTgeVJ74BOLox79+7lOpDMHWSOoQVK2oBEWjwNBmLh5TV06vDyHopeLuPHj+e+RbFl+LJmz57NXSOgpkGCmIsCilGd+HJJg6CtyaTd0+BDiTwUA4nx32NnprVXhAdo9kh8V/urnw0eR0URYI35n7xnyIuG2kpxoCpCM/Zu2TKnd0CnBVParv/OO+9w8V0oeQWBJ7+yT14w4o7hAZ12n9JCpq4HfVsR0Hv37g1yZxSXQ/FmqF70vLOzM37//XfQc2Q3X7BgAShE8Pnz50HaE70XFhbGMSH5yIu/w36XzVSMRmXTiFxoeUWi09prVqulNx0XK7Rzz549TJbMUUMnUCbgppAAvPBS3k+ys1On0Ur2uXPnuHsUwGvixImgWDCbNm0Snuffu379OqZPn46rV68q3eOf0XSmjU4rV66Ue5fsdJcvX5a7pukbqu5RJEnKi6rqHrtWNmAxGmmm0b1797h9GwTqP3UaYbWA/uFPzhygf/3111x0VsYXmvmiovQpl4Ze0ULZ+4btVEZfy6Av77746lvvgrbpG9MUYoyyKAY7PwuhGTjjS8PzJQN0A0+BGBMbnoktlcbkdUVrNgR673z+vVWBeuf1t1H1tZpc29hmIuPJAAN0BuhMczIhDyxbtkzQYn/tOtYqtHRKlvGxjRvXLspHcPbsWcZjRuIxBuhGIrSlapGs3obVrkhLpx3LpKVTZMT2S85aPKg7D48WBqkxY8YwMDcixjBANyKxGTgaFhwtlb60Y5n2TRCo1673k8F3jxrSft4l7i6qvf4W15bvv/+ec1u21H6xxHozQGeAzjQoM+AByvTFLyDa9JhkkVo6mVo+lXhw7aANfOSCbImgaMl1ZoBuBsJsyQzE6q6fWQe5yVJWLt704j51p8WBuq3/ZGFQorDXjDf0wxu60JEBOgN0JnhmwgO0s5k25BGoU5zyNnMOWgyoU2x3foZBMc9zc3MZX5mArxigm4Douoy47FnjazmmpDklTKc8uASOlDqu7fwjZg/qfBo7qjPtCKfYSKakYWUumwE6A3QmfGbGA7t37xayflEcFI/pu8wW1CWB0wXNnJLDi+MnVWZgNVXbGaCbmTCbihFYueY1E6AYR6+99hoHlhQ3nRJVUGxzQ3qo6PJt/8RcfO/VXwDzzz77rMLhNhgPVpwHGaAzQGcaupnyAMVGeustmQsgmTM++tkF5hDIi2z7b9X9SgDz+vXrs1DTZsJDDNDNpCOYdlJx7cQaaXjhwgUumii/4EgmGMf+c9A7qdjo2rp/4nN83y5YAHKqEyWMobzC1kh7S2wTA3QG6EwYzZwHKKrp5MmT5WL3Uy7QdguOGyWWeu+k/8Ft8l9444MvBDCvXbs2lyiGdrpaIvBZa50ZoJu5MFsr47F26TYjoZDQMTExsLW1FUCVNGRKkNFoaBR6JuToXWP3i7sH2uT0ep2P5cqkKJEPHjxAmzZt2OYhM8MPBuhm1iEM6HQDuspAr/T0dC57VkREBJeTk3L3UkYt3gxDZ4ps+F2bQLSNPIZee/LLDe49dzwFbWr6wsmLiy0jLoPSPcbFxQkaeUBAACj4FmUIY7lCzYNvGaAzQBcEtDKAo6W1cfHixQJw79u3T+irp0+fYsmSJfjtt9+E+zz4vlylKhcT5tuWPSEdMI/zZfeNvYnO62/JHb7rbqDVjD2Q9JmGei4+eKvu10rfom96eHhg69atSqC9evVquefLm6TG0vrEnOvLAJ0BugAS5syola1upPFSekQepOlMIK6KDidOnIC/vz9q1JDl7hS/U97flG+XyqeMYqrKpGsUVEzx+5QontnVTaetM0BngK5WYNUJMrtuWIG9c+cOl/dWESzLojvlw6UE7ZTS0dfXF+ROqPgNVf+rVavGafqUVpLy69JuVUrsXlZ5dF/V95jni2H5Q1O/MEBngK6V4GpiInZPfwK8a9cu1KlTRwko/fz8ytVPpNUfPnwY27dvV3lQ8gltwVtVP/fo0UOprgTyH3zwAcvJawJsYYBuAqKrEgx2TX+gaIm0LCwsxNixY1WCIwFkVFRUuQDd0LQgzxtVWjp/rV+/fsjJyTHLuhuaNqb4PgN0BuhM2EzMAxTMysXFRSMwnjlzxiz7iWzsPHiLz2SD5//b2dmBwgObAuAqW5kM0E0szJWN4Vh75WcitGnoyy+/FMDvl19+ASWH4MGQzhTThZ4zV9p9+umncvWlOtNs4/fff+euL1++3Gzrbq40LW+9GKAzQGfCZmIe4N3/Ro8ejaCgICVwlEqlZt1HZN8nECdg//XXX7nfr7zyCg4cOACKHMm8XuQH8fKCtTbvMUA3sTBr00nsGeMJhKloff78eW4RkdfMaTfmu+++y4Hj4MGDzRrQly5dKgxCiYmJIDCndtCuVrbhyLi8ywCdAbpZg4WpANbY5ZKnCSVVJiAkf/IjR44IILlu3Tqz7qMrV64IdV2zZg3Cw8OF/2FhYWZdd2P3s6HLY4DOAJ0JnBnwAAEfr53TDtDY2Fjhf1pamln3EZlUmjZtCvJooU1O5LHTuHFjrv6krZ8+fdqs629okDXm9xmgm4EwG7PDWVnGnQJrQ+9///1XyFBE3i4EkP/99x927NiBKVOmWKQNmjIX1axZkwP1hg0bshyjRsIZBuhGIrQ2gs2eMT+wNXSfkDtfo0aNOOCrXr26VWX9EcehGTZsGNPSjYA1DNCNQGRDgwL7vuUOBLRhiDe1kO3ZmvqSZhoU2Itv38GDB62qfebYVwzQGaAzITMRD9CGIj7F3I8//mjWvublBS9qY61atThQJ397dQHGyvt99p68MsMA3UTCzBhRnhErIz3at28vaK/Hjx+32oFVvMDbp08fq22nOfAwA3QG6EzATMADW7ZsEcB84MCBVt8HHTt2FNq7c+dOq2+vqcCdAboJhNlUnc3KNY9ZwePHj1G3bl0O4Gh3ZWUwQzx69Agffvgh1+aPPvoI9J/xo/75kQE6A3QmWEbmgb59+wraKoW1rSzARm3lF0g7depUadptzP5lgG5kYTZm57Ky9K8BVZSmhw4dqtSgRnlIeVDfsGEDA3U94w8DdD0TtKICz943PxDWV5+8ePEC3333HQdo5PmRkZFR6QCNsip98cUXHA1q164N8oLRF33Zd4rBAJ0BOhMoI/HAhAkTBO20MoeUpSiMvJbeqlUri9wJa66DBwN0IwmzuTIAq5dxZgQpKSnC9n6Ke1LZQ8oOHTpUAHWK1sj4UD98yACdAToTJgPzAG3vp5jmpJW++uqroOiElR3AcnNz0aBBA44mFPOFYr9Udproo/0M0A0szProJPYN/WgvpqLjwoULBW106tSpDLhKZO7UqVNC7HRnZ2eWpk4PWMQAXQ9ENBVQsHLNH+jT09Px5ptvcoD+008/WeX2/orw4cSJE4XBbtasWWywqyAeMUCvIAErwszsXfMH5Ir2Ubt27TjAojyhFCu8ot+ztvcpVyplNiJzFEWbvHjxIqNRBTCJAXoFiGdtwsXao98BJi4uTtA+hwwZwoBKjaxRPHhaWyBQ/+2339gsRg2dtJFPBugVIJ42BGbP6BckLYWelKCC3+r++eef49mzZwzQNcjan3/+KQx+5N5pKf1sbvVkgK6Bycyts1h9LGdwoKiCvK91QkICA6gy5Iw8gShbE9GM0tYx81T5eJ0BehmMxkC0fIxVmekm3jjTuXNnBuZaytiNGzfwxhtvcKBOO2qfP3/OaKcl7Xh5Y4CuI8F4wrEzA3pVPEDb++vXr8+BEm1tf/DgAQMlHWQsOjpamNmwdQfdZYwBug7MpkqA2TXdmc6aaTZu3DgBkFasWMHAXEf5oh20bdq0EWi4b98+RkMdaMgAXQdiWTMQsbZVfGC6cOECqlatyoFR8+bNK/32/vLy1L1790CzG7Kn04IyBfQq77cq23sM0BmgM2HRAw/Qop6DgwMHQq+99hrS0tIYXStAVwqtyy8q9+rVi9FSS1oyQNeSUJVtpGft1U1jnz9/vgBA06dPZwCkB7ny9fUVaBofH89oqgVNGaBrQSQGbrqBW2Wj1+3btwXvjF9//RUFBQUMfPQgV1lZWaB0daSpf/DBB8jMzGR0LYOuDNDLIFBlAyfWXt0GL1rE8/T05ECnSpUqoIBTjIa60VATvSihNG968fb2ZrQtA68YoJdBIE3Mxu7pT3AtlZZiW29ISAgDHAPIU2BgoADq69atYzTWQGMG6BqIY6kgw+ptnIGGTAJkCiANktKq5eTkMLAxgDw9ffoUX375JUfnd955B3fu3GF0VkNnBuhqCMNA0TigaGg6k0mE3N5UHXl5eRUCBnHC4127dlXoW4amg6V/X5xcu2XLlnpxCaX4Oqr4wpJ3qDJAZ4BuNUBUWFgISvW2evVqUIqzJk2a4O233xam67wtlj9TzJAff/wR3bt3x5w5c3Dw4EGtfZ5pwwv/HT8/P6uhoTkD//DhwwWaR0VFaU1zGtRv3ryJLVu2gDZ+0calunXrCt/i+1F8rlevHjp06IDw8HCQHf/+/ftal2dKGjJAZ4BuEYyqTkhIWJOSkuDj44MaNWpoFFKxwGr6TZ4qlGVI3YYWSp/2zTffcGW9++67ePjwoUXTUB1tze06hVVo2LAhR/fXX38dV69e1Uh3Css7aNAgvPfee3rhi88++wzjx48HeTWZG234+jBAZ4ButszJM6mq86NHj0AhV7/99luVwvpmrTr4xakFOvQZiUFTYzBk+iqlo+eIGXBu3Rkff0mxV15W+g7luuzduzdOnz4tR6PRo0cLz9JsQFX92DXDmOzOnDkj7MZ1cnICzcrEtCbQp4VTSmmnatB+tUZNfPerFK39BiA4bLESTxCfBI1fgBY+ffBVQxtUrVZd6TuUrIQ8m3bs2KFUvrgupvjNAJ0BupxAmIIJdSnz7t276NGjh5AQgRfaN96ujbY9hmDsonjEHLqL+Cv/D9uvQutj4z/PMX39MQSMnoN63/+mJMR2dnbc1PvcuXNCHswWLVroxZarS/vZs8WYPHmy0D8REREc/9KsibTnOnXqCPeINwiQadAe9mcsFiVextbUYq15gvjnr3+LMC/+PKcU2Lq0Vhr4KTTBvHnzzAbYGaAzQLcIQCfTCgW7Ii8HHsTp3OA3JwydsQabL+brJKhlgf2fm0/DzTsA1V97Xa48HjDIvHP9+nWLoJ21DQK0cUsikXD9Uq1aNaxatUqIcMnzxkeffQ3/0JlYm5ylV75Ytv82OvYbh3fqfCjHF46Ojrh06ZLJ+YEBOgN0kzNhWYBDNksPDw+RAL2Mlh0DEbkjRa/Cqgrk1595isDxkaj9vvwiWs+ePc2ebmXR1ZLvE3hSzBwewPkzmdkmr/gb2y7/n0F5gzT3UfM3c2YZvmxKo0czBkUzkDHpzACdAbrZAhNp5UuXLsWbb74pCO7H9b7DjA3HDSqsqoA99vQT2Df/XagHCTHFGmHb0Q1jKy8LBCmJCD9bor6oUfMtzh6uq6lNVV/rcm3rpf+hx/DpqFpNlhOV6kLmOVMlu2aAzgDdLAGdtBxakOS1n5dfrsItcOrbtKKL8NKz4xfvRO33PxbqRRteWGRF44I6DfK0MMnzxhf1f8LKIxlGH+TFvEP2+fq/OAp1IpNcYmKi0WWLAToDdKMzXVnaF234ITdEXmA//ep7zNp00qQCKxbeDWefcSYfvn6UDJq8L8pqF7tfceCfMWOGwBe0EE6LncbWysW8IP5NC64Bo2ajWnWZKYhi4xs7VAEDdAboZgVE+fn5QrArAswf7V2x4WyO2YC5WID7TlgogAvV9eTJk2ZFS2sbQGiTDz+I1vnwU0TtvmqWfBGx7ghnAuLrSm6uxuoLBugM0I3GbGUxNSWJoKTKvCDYuXrq3XtFDMj6+N1vUpRQ3+rVq5e52aUsGrD7qrX4yMhIgc51v/gWyw+kmyWY8zw1Z+s/Qn2Jn7dv324UOWOAzgDdKIymDVANGDBAEILfnD2wJaXQrIWWF94ug0r9oilIV0ZGhtnQVBu6m/szsbGxAl988Ek9rDh83yL4YsrK0vAQ5AFz+PBhg/MFA3QG6AZnMm0Ag3bd8Zr59zaNsen8C4sQWh7U+05cJNS/ffv2ZkFTbehu7s+Qyyrv5VTrvY+wNOmGRfEFeWTxexloAZ0CghmS5gzQGaAblMG0ZV4xoDewaWTRgE5BnbRtN3tOtYmFpwsDdM304enEnxmgM0A3OfhkZ2cL0e9oA0/sqccWpYXxWnqbrgMFLZ0SX/BCxviSzZ4AACAASURBVM66gRJPL9qH4O7uztGU3FbNydOJ73NtziPmbBT4YuDAgQblCwboDNANymC8cGo6U1Z33twyfslOiwRzEuy4c7kgGy+1hTa9PHjwwOS01UR3c78XExMj8EWHwFEWyxfkVunYooPQFgrTbCjaM0BngG4w5tKGaWnzBQ/mTdp1s1ih5TW1P1YfENrTsWNHk9JWG/qb6zOUlYiPZf9JvQZm7+3E97+686pjD/HmO+9yvPH1118bLLsVA3QG6CYDHYo3/umnn3JMTsGO1p3MtnhAJ4H26NxPAPVNmzaZjL7mCtZl1YtMLZSEggZ6MrXM2JhsFXwxbNY6gS+GDBliEL5ggM4A3SCMVZbQ0v3p06cLDD5mwVarEFoCdNoI9V7dz7m21a9fn4XY1VHGjh49KvCFl/8wq+ELMr1Imrbl2kbZsigUtDZyosszDNB1ZDZdiMueVb8YRpuIvvrqK465yU1R3VTVUq9TogTelETp6hgvqOcFRdp069aNo12Nmm+C4tRbKg+oqvfivdcEvqC47optr+h/BugM0PXOVNow5e7duwXGpngcqpjfkq9tupAHijVCoM5s6dqDOWWiok04RLdWfv2tji+IpynEL7WPzI36DrWrM6BTUH9tVu+pYy5fvlwusCDne0M74GsDOuwZ7QVRV1rR5htiakoVtyWlwCoFt51/CNdGCtLEdo9qx0uUVpD4go752y9aJV+MXvCX0Mb4+PhyYaQ6edMZ0CkKXoMGDTRWIisrS8ggomu0MVooowS8P/30E5epW13FtblOwZKio6PLfVCmcG3KYc9oJ6w8nciDoUqVKhxTt+8dapVCS5rYol1XBMGdOnUq46UyZsO0GMrniKVMVJY8Q9NUd0qOwSdMad26tV75QmdAr1evHjRlayHNunHjxqBce3zuR11tiPv37+eykVD2dUo3xQOBrufQ0FBBoPhRX5fzli1byl22rnWtTM+Lc0Iu+fu61QouCfVPDk05HqQYLwRYlamfdW0r4QQvn5RWUBMoWvq9Tv0nCG29deuW3vhCK0B//Pgxl/mcHOKJ4ASUlAmdPyjTNnXef//9BwcHBy72woULFzgwbtasGSjY+65du3SqNO20o7ImTpyo03tiJqJ6kiZ4//59nQ7eN5oBum6at5j2mn43bSoDOWtcDFUEGvHiKJvxaeYnSvJMMk+xT0ydyESxH/X9n2LS8IPXmjVryo1xinKmFaCTnYcvXNWZ8vulpqbi448/xvvvv49///1XqCB5M/Cr1nPmzBGuK1ZE1f/Fixdz5e7du1en9/hv8YDO/9f2fOLECa5cBuiaBVBbeoqfI36oWbMmR19KtqtvQTG370XvuyXIDkUNFNOC/ZbnrxYtZIuFFAPf3PrREPXhM18FBwfrjS+0AvScnBwuznOnTp04V7OrV69y//kzxfqlrc6UuSUgIACUVUR8kL8x31lDhw7V2oxCU9QffvgBNF0tj+mFN7mMHDkSuhxkKqKBiwG6vMDpA4Bo4OeVAlocMoSgmNM3yfe45lu1uDaPGDFCb4Krj74wp2+QrPM5Qmkx2Zz60FB1oXj/JAtSqVRvfKEVoPMdT1tWaTS5ceMGNm/eDNK2rl27xpk1vvvuO+46LWbSb8XjyJEjoMwd1ABdphgffPAB905cXJzOjeYB/bPPPkN5Dl3NRDyd2Fn9QCCObU3aq76FpUOfkfj2J3tQQCTxt8mThuJp0L3hs9fL3RM/Z4jfvB29efPmOvNwZeGl9PR0Ts4JHwxhP6ddmtT3Pn3HKvU9zRTpnnfgaKV7huAH/pu8Hf3111/Xm/ui1oBO7opEbDK/REXJsrQ8f/6cY9BFixaBIuZpw3wE7NouDv3zjyzrx3vvvQeyxWvzffEz5TW5iL/BfqsH5/LQZvjw4RwfkdZqiFyQlP6L+PTjet9h2+X/EwTU3bcvd92+uZfcdV64DHn26iVrc+3atbXm/fLQ1pLf2bp1K9c/1HcLEi4J/aavfok9/QSvv/E2XqlaDSsO3xO+T4MHlfnRZ19j7Yn/hOv6KlfTd8Ys3Ca0WWymrkg/ag3oEyZMQK1atUAJfBUBnSqwYMECzJs3T+4g90Vx5cj7RZewohRqkuzyvG+qrn7tBOi0xZavAw1AT58+1frg32Nn/YF6y5YtOSYmrVUTs1fk3s+Ozbky+HACg6at4P5/Uf9nk+w8FMfwoPjejJ+U+Yn3fKr+ag1QsuWK9L+6dzsPmMTxAQ2w9My8+Aug8gjoFyVeNkiZ6upC1ymNHg0mdOjq3q2Oh7QCdErcS/ZxX19fkA9xREQEV4m0tDTuP2nctHmCbGCUleOTTz7h7qekpHDxOvr3788x8RtvvAHKDaiuMuLr5I9OmUqCgoJAA8Nrr72GQYMGafUu/x16nqYz/H87OzuBgDwhNZ21nUnw32dnZUFVpEmjRo24Pmjk0dFgAjR9/TGujIa2zqDcjpSF/e3a75ssD2VYzF6B78iBQJEm7H8xt8ZFskj+2ZpAsCL31p95ippvvsMlcI45dBcffvoVqlR5BWHL9xisTE31pd3EPP4sXbpUL3yhFaDTomi1atWEwvlK8Ge6T4BOm3iIOQnI6R6dBw8ezEVOo+u6APrcuXOFb9C7/v7+nPvjvXv3tG54nz598O677wrPkzsi2e+1PZiglQ3QutLIGIBOQsRvr6YojlWrVQelAtMkXHSPbPo0CIhNNWW9o819Buhl8xE5LRBmGBLQqa/4/K+Uzo7K6zNuvkq+oBSI/qEzQa613/woQZtug7DySIbKZ7XhAVXPmAzQSWh37tyJ9evXc0fv3r05YqxevZr7T/EI9AnoNCOgwE2tWrUSwJhs+DSoBAYGCtfKApOuXbtyJpuynmP3yxY4fdHIWIAevmo/x6MktEOnry5TEEmTr/PRZ9zimCrhq8g1Buhl85exAJ20dJqxEV+07Bioch2HkpPX/9mBM8fQIqr/yFl4/+MvuFnemuRHZfKStrxiUkAXC7QqGzoB+ssvv8x5vPDbusuroY8ZM4YjeFJSkhx4k4cN2cS1taXb29tzLkEXL17kNijRJiVdj2PHjsnVQUwH9rtsQVWkkTEAnWywfJhSElxNWZBIEyOhrfJKVY7nWvsN0JvA8oLNAL1sPjEWoHcfJjMXE1+oy4I0IHwZxwvUb3wfkr2b7O369IQxS0An7ZzcFwnQKZXYypUrQXEriGDlAfQrV65wppXffvuN+64YEOgeAXqXLl3KBFmqF9nPSaOnmQXVpzzHrFmzyixLXEf2W7PwGgPQe4+RmetIq6I+/8mxmSCYvIDSOXLnv6CFUnrmB0kT7jxgSrTKZ8Xv6fqbAbpmniCZMQagkwcUmd8oCiaF5qUMQhS7XrE/2/YYwmnkil5Y5Akjbemt9Lzi+9r+NwtAp6hxtEGChIA8FmjhkrY068PkQiBMoQMoVIC6xaOQEFkEO8o3qAk8eZfHZcuWgUITUIRI/qCFXYpJY2Njw0XB46/TmeIqiP/zrpmaymL3yhZYnkY8oOtTMMQCNHYR7Wp+GWQjJfe0rxracLxKqeHEz9Fv0sQou1DkjhTwLmTz4s8rPaf4nq7/Jy0rDRWsjq95+lTWMw/otOahK321eZ7ikBOA0yLolJX74Nl9MMcXXYeEqyxPEcwphRwNBuq0em3qoPgM5aDllUyjLoqS/ZzAjxYY+QrQmUwao0aN4kLdEqDTxgnyLCHbNd3XRUMnLZ9PFrxw4UK1YE1ukxS0i7RvTb6bfNiA8+fPK30rLCyMs8cr3psyZQrnpaPLwmtlFcDytpuidRJvfPndLyoFSZHpdfk/56+zXBwQbhG0JG0ZH6q0gU0jlfZS/vs+QWO4KfXWS//Te70Cx0cKckNxkcpLO2t+j1yeeWxRpTXz/VSeM6U2rPvFt9z3qS/oGzTYk086eb2Qj7qm75JN3ca5FV57/Q1u4VzTs7rcm7vtnNBmwlh99K9WXi6UjIB8yMmFkDYRUT48Ir5YeyVAJ7dACubv4eHB3dcW0Ekz9/Pz497x9vYus2FkQ6d4IKRl02KpKkKQVwzNHujb4vvk6UI2/kmTJsldp2dotxr5vdNuVyZ42mvdYvqW9Zs3x5Ew6TMOOrmh8SFJB0esFASUPFY+/ep7jrc0uaeR7/p3v0qF93QRzLKebd6hF1c+7bQuiz6V9f6hQ4c4GhGukGmkLJpqe5/AmDenufn0lhvUW/j04crsFDxebXmxpx6DeIOUBLFNXdvyNT03aGqM0GYKIKiPvtcK0BULUrcoqsptMTMzU8idp8ptkTxaCMSpI2kw0DZmC+0sI68XAmBFTZ20fYr/QjFZxHWn6S5lEqfyFIGenqPQv6tWyVKHubi4aF0XcRnst+aBgI9kSf1NGrUmhtflXreQqSDf9h7Dpyt9kxZF6R4tiKn6JoE+bS6habiq+xW9RrMRai/NThh/qOYP2vBHNKKjz9h5eusHmqFR39NOYQJ3cV9S6Ga65+YdoHIz08LEVG4HKZmBDJGomhbgqb1169bVG18YBNApdC5VVAy0BLK0OYh2lPJMTRo8mU/oWYqxTs/w97Q5EziQvZ1MQQTw/Du064q+KY7D/vfff+Ojjz4ChRGghU4K1dm3b18O3MluT9fpHfFBO035b7KzakHUlS60PsHTmGzYYgEz1W8+EUXIzLV6rw/NQngPGpbkQjMP8cktmv3eU+/9oCtv0WyuRs23OB90cagAXb+j6XmaEZIs6DPJhd4BnUCQTBbVq1fnFhfPnj3LVZhMNlT5HTt2CCBJtmzyWiHzR3l3ZR4+fJjT0imLEtnXCWBoRysFBxN/848//uDKJ1MNBeqigcTNzY17luKLzJ8/H9u2bcO5c+c4c0u/fv245yn2jK6gxZ7XLLg0qyJe8OgSbHLBJYHj43ks3pOm9/rQLIQfwFiwN818QTN0otUX9X/Sez9oAlbFe7RATiZBF08/g8VlJ9faV2vIwkiPGzdObxhTLkCncLkULIsHUAIwd3d3JCQkcDEJBgwYgD179nCVJFs0mT5IA1eMh05mD/JGqSgAUhni5AE0fVP0H6e68ok4tCkvNzcXtDir66xBm29X9mc8PWVhQz/7uqGcTVNRsIz1v03XgdzimKJngz7K510oCagePnxYYV63Zt7hQ4qQJ8ra5CyTgPrSpJvc4jiFtjVUTBniq9lbzggDPUWu1Ve/lgvQ9VU4+45mjcVa6cN7IBHIGcI2qSsQU+hUWvjS9b2ynqcBggYtaic5DFhrf+qrXbQBkGhFB+3OLIu+hrhPs0Yqn2L/fPDJl3IHBffSV5ktOwVx5ZDJmDK96YuGDNDLSFyrL0Kz75QOXjSDogVyEhxzsJfSYunEpYl6E1Ze6PlQvtTO5cuX601orZmXeNPsR59/o/eYOny/aDr3n7IUXQaGqTz+3HRKLzxCbpnkAskNXP7+euULBugM0PXKUNqCDS1IE0NTXA1yDdMkZJZ6j2yw1EbyrKIAdtrSpjI/t3btWo5mRLcpK5Kski/6TZLlk6A2UrpLffY3A3QG6HplKG2Zk9/JS0xNdmZLBW119SYbMPkuU/sorr+2dKnsz9E6F7+B0VC7idX1mTGukxmODzdB4U303d8M0Bmg652ptGVSchclwPv4y/owxA5NYwioujK6h0wTNE2yDWtLE/ZcMYYNG8bRjtw9acOYOhpb4nWxGY7WkvTd3wzQGaDrnam0ZVIK5EaATkfPETOsRnCX7b8t2EidnZ1NRl9t+8HcnqMgfDxfUNRMQ3gfmWIwoI1N5JJJbaNd7LSWpG/aM0BngK53ptKWScltldfSq1Z7FbTBxxSCps8yCXx+kbpxQkt7LE6fPm0y+mrbD+b4HB9ehMCPUvjps49M9S0+BR61SVO8qor0BwN0BugmBRzaTUyb0IjJaeecIX1/jSHIA6ZEC9rl2LFjTUrbigCDqd+lRWRKckN8QeFuKdqhMfrPUGVQFE9+x7Crq6vB9rcwQGeAbnLQ4QN2kfAGjJ5jsYK7/OAdLs42taNhw4ZyG+9MDZCWWP6BAweEwdGxRQeL5Yu//i1CvQayECcUJfbatWsGkzkG6AzQDcZc2oIIBWSztbXlhJeywlBQJENpSob6Ls0s+DymFM1T3+5o2tLS2p6jXec0QNJhiFg7huIH8XfFphYKE2zIPmKAzgDdoAymLfNS3J22bdsKwkvR8SxlMWzq2kNCnkryOU9NTTULmmpLe3N/bvr06QJf0K7ejf88t4gBf8Xh+9xOU35AiouLMzhfMEBngG5wJtMWMCi7FM/8tFPQEuymNOi085dl0aK6k31Ul5hB2tKmMj936tQpYWcxBbQyh3ARYg1c3e+R8zZxeZaJLz755BMuG5qh+5EBOgN0swF0YnYKbcyDOmWZoeS86gTG1NcpjjoF9uLrS/Fanjx5Ylb0NDSAGOv7+/fvx6uvvsrRmrbNq0opaGp+EJdPETwpyBjxRp06dYw2a2OAzgDd7ABo4sSJAkjW+fBTs3RnpIUu13bdhXpSyOhHjx6ZHS2NBbjGKIeivPIeUeTmOi5qu1kO9kHjFwh8UatWLaO6rjJAZ4BuliA0c+ZMQShomk1CQhqxWAsy1W9yQeO9FkgDc3R01GvEPGOAo6WWsXfvXi6fMD8rohkSJVs2FS+Iy119PBMUroCv24cffgjFvMWGpjsDdAboZgnoxPiU0pA25/AC0tDOBZQ2TCxExvxNO/18B0wU/ImpXpQHgFIXGlpQ2fdLo3UeP35ciPdCfUBhbsNX7TcZX9A6yvDZ6/HmO+8KvEo+9GlpaUbnCwboDNCNznS6gNOZM2fw888/C4JS/bXXuWBextbWKfMQv22bQIT8ickFjSVAKQVaXfq1os9SUuX27dsLfMENrr59QaFpjTnIrzr6APbNveTqERwcbJBt/drQjAE6A3SzBnRiYkokTukKq1atKggORayjXZmGdGEjzYuCKVEYXH6Bi4CDPFkMuTlEG8Flz8gGkg0bNnCLjtQvdNR+vy66DJoMchk0JLBTukIv/2Fcpiu+7Hr16oEWb03ZNwzQGaCblAF1YX6yR9rY2AigToJUo+abXG7SefEX9CbAsaefoM+4+UK2IV5gKSlHVFSUXK5aXerPnjWMNk+p/fh8pHxf0QDs6NYelOxZX7M5WggnV8SfHJvJ8SCVOXjwYLOIec8AnQG6xQA6ASLtKqWwo+RVwgsvf67/swM6BI5C6Nw4LN57TWtBpgQbU1bu49KeNWrVicspyX+TzrRZiGKai/PWMnA2DDhXhK47d+5Ey5Ytlfjiw0+/4txLB02NAS1oEzBro71vupCHWZtOghJStPDpg3fe/UDu2zRj9PHxAdn0K1Jvfb7LAJ0Butkwoy6MTTtLKRF49+7dBf9kMQjT7xo130JDW2dOGD0694Pi4dD8d7z/8RdyQir+hr29PZc6jmUbMj/w1sQrtBgZGhoqZ4oR9yslHvmqoQ2X/lCRJ+g/mdg+++YHOTOb+P3PP/8cf/zxB8iOr6keprjHAJ0Butkxpa6CkJWVhdmzZ8PFxQVvvfWWWoAWC6Wq3xSD5YcffgClx6PFWF3rwZ43L+DPy8vD+vXr4enpibp165abL4hXvvzyS86sk5CQYNYL4QzQGaBbFXCR5k4a2saNGzFq1CjOrbBBgwZQdUgkEvTp04eziycnJyM3N9eqaMEGGPkBJiMjAwTI4eHh8Pb25gZvVXxBXlVdunQB7YVISkqyqD0GDNAZoDMQYzzAeMBKeIABupV0JNPG5LUxRg9Gj8rIAwzQGaAz7YzxAOMBK+EBBuhW0pGVURthbWZaOOMBeR5ggM4AnWlnjAcYD1gJDzBA10tHFuLuxTO4+bRIWTCeXkNy0mGkZhWh+MUdpKZlo0hDmUVZV3Hy2DmkP5cfeUs1kXxkpJ7AicuZKNTwndLn1X2nPNef4frJAzh+RXMbDFN2eepbsXfy753Dwf1nkf6iPN/Jx8MraXhQqOLdwnScPvAP7uWquGeIPi16gpsn9yL5ZoEyf5aUV5R9Cfu2JyGF+LSsOhRkIC0tGwVlPWfU+0XIupaK9Bzl+hc9SsWJ02l4lG8kehu13fJtMhGgv0DSWFdImnqjd1AQgrQ+AuHbQgKHQVvlme75FWz7IxBeTaWws7WHi2dPTFh/Ho+L5BurjlGL7m3ByA5e8PKSHb4RB/FCh055mjQeLRw6Y1GqssAUXIlCFwdPRJzKR3FRJg5FdEIj1wBEX8yRb0NJeS8OToSbfTdEXyssuV+I68u6Q9o1GmkEDkWZ2NjPHg6Dt+GZmjoWpC5CZ4kNt02etsrrcth5RuAUz/hFj3B89SwsTLwmE96CK4jq4gDPiJN4mDAB3iX04ummePaekKDcxrxDCGspQevgaVxwKwpwpfKYOwE9XO3ReVGq8YGj8B4Sx7SBo+cYxG2aAE+pJ8Ym3tVxAC3AzbiBaN6oM+adEUVjLLiC6B6N4DogDumqwJ7v04IURHaUoHHbHugXHAwK+KT56Ad/L2dIfBfgUoEi3xciPTYIjZuGYtdjxXuy/wUpkejo6I255/OV+4yvE3fORkJoU0i7LsXVknKKHsRjXKf2XLAsCphVenihRSNb2LmH4XCeuNxC3FjWHfaO7ujU0x/+/toeXdC6kQQd5pxTqmP+uTlo7+CFmadfyN97cgiT29jBzr0Hho8ejdGiY/zyZLUypA4rzP26SQHdsf9mZIuYpSjrb/zRIwhRZxQ6RXgmF3tGucBRDtCf4HC4JyQufpgcm4TkEwcRN70nmkncMGLnA43asNA5T1OwO3YN1qxZjFAvCRqH7kKuUKaYEVX8LnqE+BBXuAzYhPsqBhA5QKdvFtxCYvRqJD9QBn+qTymgF6CwkLSNPCT/0RrSgVvwmN7XFtAdO2DOuVxuqzxtly/7yMPNGH84igG98CaW93CA++QjyOPqXgroj1O2Y2lUFOfDTfFN5I8FGOljD4d+G+WFi77BAbojAlbf1dw3+f/gTy9H4wN6wR3sCfOGU2M/RHJA/ASn5/mhUaOOCE+6V8bgUoRH53ZhU1wcKH9k3MYlGO3fE2MWrJX9j4tD7IzeaCJpgf7z1wvXdpy+rzxYcIDuCO+555FPdCvzKEDqIl84igG9MB2Js0YgJCQEIcGd0FTqjq4DQzBs/Br8c/80/opZzu2EXb58OaJn9kVLiRsCI6KFa8tjNuDIHV6xkNWhKCMO/Z2bYPBfDzX3X3Ex8i4vh39jKfyiUhXaIAN0xzbTkCwH9GW0s+ASFvg6qgD0HBye3ApOPZbjmtwg+RSn53SC1NkHg8PCuABvFOQtLGwwfJwlcBu/Dzll0rWMOpnZ++YD6EWZSAprB4nEDb7BA7nYGRQ/g45B42NLtA4VgP5kJ4Y5S+C3+GqpsBXdRWyQFI591uKuCpBVKxxF97Eu0F4nQM+/tAh+Uk+EHyUtLBeX9yfgRDqvfRfg8ek/4WPvhn5/rsDiuVMxfnh/BHTxgofnJCSJptz5Z1ZgwsIDuLufNHQ/TPuzH9qN3YOnhfexNtAekha+CORmMgHo4GoLu+Y+6COa2QTP2IOHJW3lNHSttC0xsxYifWUvLQH9lIKAir9Dv3OROKKRBkC3g8RBCicnJw2HFBJbiXEBPecqtoz2glTaAWF77pTyU+Fd7J7gBUfHthgem4InaoU4H+fnekMibYn2vr7wFR2eTSSwdW4FH9E1X19veDSWlA6Y4u9ygO4Ar/AkXLt5k4sjQ7Fk1B/XcDCigwKg38We+WNFWukoDOzUBBKPKTh0LhIdJRK4uHtyOyk93ZvAnma3/H8PVzhKPBB+LE80mOTh3FxvOLabhuScYhQX3sLh+H1IzVJWTooeHUFERymcOs/F6aeK/KEG0J/vxUQvX8w6JlboivBwSyh8gmOQkqsa0AvTN6CfixtCEzJRVJyDSwf24FxGDtITRqONxAZ2HuOwN5M3xRTi1sb+aNq4B6IvK9dbLTaI+8aMf5sHoBc9xJG5PdDEzhndp23A9h07sIOO+FUY5y2Fc9A63OJGXmVAL3p4AFET/0BciniqmIcjYe6w956L87z5QJtO0BXQizKxc4Qbmg/dymnnxFjBLk0wIDYBkb3awc1ZAlvO5GEHJzcv+PoHI2RcOGZHrcTGnaeQLqpbVlwwnIPjcP+AzOSy5EA0eriPwu57CRjh4givAZO5HW7h4RMR2MoOEs++CAsPL7kWjohVx5GtDtDznyErMxOZKo8nJeYlYwK6A/zmHUPq5cu4rO64tBMTPR2MBug5V+MR5usCOydvTNl7T4XGfBdJEX5wsWsM7zGxOJfNA4QYrGSA7th5EVLlzB4yvqUZS6ZYwSi6hzV9HDUAukQncxmZ1lSbXErqmJ+CSF8p2kWcxDMysTi0w4zTMrlRNLkU3liG7g7ygF6U8RcGu7ph2Haa+Rbh0a5RaOHYCfPPiwG4GAV392G6nwtsJd6YfVb+ngwwSwH9+N2rSCsBW1JEfKV+WHw1H8+e5pTMAGSyLA2MRUaeKkDPQfLUdnD2j0FaQTEKb6xCQGN3DJ06Gl6OUviEr8Zcfxd4DNuG2wVFyD4Zie4uzui++KJOZlVLAXqTA3pW9mlE928FqWs3TIoYhNZNOyMs/gqevkjH3xF+aOI+BJtu8COpMqCrJPTTZET8LoFLSDyyxAJUFqjrBOhFeHR0GrydffHn/os4c3QPVoV6QuobiQu595G8eS02Jx7EyUPz0c3eBaP2aNpWXoi0pV3hGroLj3kb+tUrWNLVDQPHDkJTaSDW3ikBEK1NLqX20LzkaWhjp8aW7jAU27mZgjEB3R7eEzcgITERieqOndEY6m4EQH+RjkPRofB2toWj51CsPFu64PviyFwEBEzFHmGh8DmuxofB19kW9u6BmLk9VWGdRgboDt4R2H81jQtBQGEI0tJSETvIGfb+UTjL/efvnURkN5FJS8yfvIY+7SDu3L/PBYKiYFBlHRmZz0pnWjWBegAAE2JJREFUFuLvFZdopi5BiL1VCA7AdQH0wgwkTfKCk89U7Dy2H4lblmHk747wmLBPZDZ9jht75yKwpQSObQLQr1MTOLTsgzl/31IAzxJAbz0ec0d7wDVgGVKeFyE7fiicm4/H3+eWoLtHEFam5qK48DqiuzvCa+Zp5KswuTy7EIWezh4IjT2IpPhYzAl2h3OvFUh7cBArlh9CRmExCq5vwuCWTvAaHIrurvZoNYLAXTwQW89vkwN6dkE6EiLnIyHtOYqL85GeNANdmzjBrWUTOLYZhrjLdJ0nuCZAL8TtAysROXMC+nk1hqRFf6y7LJ4u8t/QcNYJ0HOwZ7SrTAOXSOHqIoWNnQcm7CsFBK7eT7dhsKMDBmzJFtpRlJuF2ymncT6dB/kXODjRnWPaZzygX8vDzf1LMfx3ezgFri1dQCsvoEuDsPq6vJZ+b8coNJUaGdDzT2NBgLdo4Uy8iKb42wchsdeVtWWBHzT0pRbPFN6KxxivRrC1dUaHETE4JUzLZd/N3RECqX0gYjPktfGctET8GdQKjrYStOi7CqnCTKvE5KLTQrSdeg3dh2zoFzjz1vPMdNzSaHIhc8wtpGfyPCVPm/xr69DPtRH8Fsk0Uw7QJS7wDZkim+WFdkVTiSv8QktmfWN6ooXY5PI8CeOa28LGVoLGbp7wcJHA1nUQtnA29jxknNmMWcGekNo2gldIDE5mFqL4xU3sjugGV4krukbswS3BXl6qoSen78F4Tynajt+J+DB3NAreiIf5t7FliBukHSJw5MZmDGzUBKGJT1GsBOil9LaTNkUrdxfYSbwQkSxahCY+KMzEoanekNjYwLZJP6xNUzVrkKdXKeZY1nXTAzoneHnISkvGzpgIhPi1gFMTb/Qb1A0tpc5oGzgJS7afxI3HpKVrAvQCpKwejp5+v8NNagup1zCsOpNV5sKNXMfpBOjFyEm/hItp9/Ak9zY29ndFs8FbRDb7QjzPvImLRxahTyMJ3P1HYHiwPzp5NocT54EiKV3w4rQQZwzYkoVcAdALUfzsIMJae2Ds36WDgfaLogoaurQ/NmfLM+eL/RPQXCdAv1zi5XIK+QVXsH1eBCIiVB1/YKCXRLUNXQuglesTxeefnEbsTFVlan9txsqjMtNHwXVs+iMMMcfuyhZ9FcpSB+iy+j3D1cQFmPtXmmg9ocTk4rsQKS/EC9HPsCvUGQ5B6/EgX3Q9Px2rA9SYXPJPY2Y7R/gtSUNh8QscnNSixHynZqbFDSK2aBl2SKktRVlHMaOTFHauIYh/KBucZIDeCF6BIbJF06AOcLFzRvugkv/BneAqBvTiF3h48wYynhag8O5fGNrcBb1XXUNB0QMkjPWEo40Err6hWJJ0XWGhMRdp28ahvZME7qMS8ICbMYsAPa8YOecWobuzIxwdJOgWfY0bwIse7sX4Ng5o2d4LLo0HYDMNtkqAXozCzDRcvP4QOfl3sWVwc7iN2CGsJRFepB9bjYndmkMi9cSgOQsx3tcFEhdvhCxIQIoK279G3lPgD3N81sSAvgk3k6ahSwsnSCRN4BUwElPnr8OxDJmJJef2ccTNCUWPVo1gZ98U/otOYPtIRS8XeZAiIuc/PIXl/d0hce2LWMH9T/k5pQ7REdBl7xfhYUIoWjYJxJprsnrnnZyLLs2lnEZgY2MLW1sb2Ht0Q8j4aZgfHYv4pGRcvJmJ5/yKfOEt7J47HXGpBSIvF5l3wYu76XjIP0cMVW4NXQ+Ann8Oczo4wHv+RRTkn8aSgQFqXM56on0zCewFL5d8nIseiK5+fvAr79FzFg7mFqPoUQLCusovOIoXH7X57Td2S+mMR4OQagZ0VfxUAuj6sKGXeAP1WXufU0rycx4jOzu7zOPxc948WVK/J+cQHdhUGAyk7UKw+txj5JfDhs7xOwF4qDucey5DaonGnXs5CfFHbuCZWvNmER4e24KEVN5ZQB7Qi8kctDYIje2aYtSep8JM9nHyDHg72MAhYLWsv1QAOi+Dj/aOhYdrEGJvktw8RWrCAozq1hIOtk7wDJ6NnZefyJS73HQcjB6NLs0ksG3UGv4j52LnFdWzGiV80MAr5vKsiQF9M7KfpyH5wFnczC5AceFdbB3hAacmv6NfWAz2XS+ZOhXl4O6FE7iU+VyF26IqwSLB343RLSTwjDihpLGoJX45AL3wznaM8HBF4Oo0FBQX4fn9FCQfTMCm2G34O/kCbmRmIj6kMed2yLtoPk6OxPAJcUhVsXmo1G2xxF0sJxFjPZqjeXP+aAZnexvYODijmXDNHUExVL6MFopeLpwNXR8a+ot9GN/MoWyXQyUvl0KkH1yH6KVLsVTVsWQ2BrWRoJHfeESpuk/Xlu/GFSPbPcsL6BJ7F7Tw8ICH6GjmZAsbqSvcRdc8PNzh6qjGyyUnAcMaO2FofBaeZsmbylQvboueyX7O8UJR9mks6uUKSfNAjB/SFg5eozBrRFs4ugQgesdcnRdFi4sLcHPzYLRsEoCYy/kozsvE5WMnkPY4DYmLZnHhZinkrKrjz5iDuC8oJoqAnoczs7wgsbGFo88snHom4+OirASMaGoLu5ahSHigWkMnWS56sAdj2zRBQMwV5BfnI/vaccRNH4SgYeGI2nwUKSoW3lPP7UfswgiMGxWJQ8IaiWosUYsXZgjwpgd0JaLk4eH5BESN9IWrtAUGrpdNwWREVTC55N/GiYQEnEqX95WVPZuDhOHOcKDVcbWag0IH6gjoBRlHMbeHCyQeQQibPBwBHZpzdlXPiGTRIFKAq4v9YO82EQdIw8zYjTGtHeAxMgH3BAYvrYcSoOdfxZ6Vpf7Cy5cvwnAvCSTeo7B4OX89BlvPPBLMSyoB3d4TfafImyWmDvWG1FGDDb3oIZIiRyN8k2xzT2HaEvg5tETY4bLWJjS4LZKv/cn56N1jGvY+KrFNF97GCn8HNJ+wX2HxrJQuphAq3QG9CNmph7BbaaF3B2b3coLEdwo2K93bhf0Xyd1Ovq20f8HP8XfMPnUQ4R52Onm7SLpEcYNf0b1YBHsGY+X5bJyf5w1Hn0hczE3HnpVbkcK5LTrCrX3JrMnbHVJbKVp6l/zv6IFGciaXPKQnTYNvI3u06jsRkwZ3RWvy4nIegE3pp7E4uGvp7MurOSS2TnD3KZ2RdR+5nvNCkfWjAqA/248J7o7w+3M1wtpJ0T7iOJ4UF+LmygA4OXujs5cUHuP2IjNf2culKPsclgc1haRFb0yYHAJ/ryaQ2DWGX9RFFOTuQIhUvYnKPjgOjxTobgo+02eZZgLohbizeyEiFq7BjiMpuJdDAF2I7NRknKeRWSC6AqDn7sFoFwf0VrlJJRt/DZJCOmAzsoT35YWm9Lsl13UE9OcHJqKFnQTOHt7oOXAsZsXE4+iVTBGYy76bf3oG2tl7YdaBQ5jt5wxpx5lIfixuV2m9lABdse7lMLkUXNuBOWETMXGiimNyLP7hFvVUeLnIlV2I9FUBcHQJwQ4FW7wSHZU09NL2kV3z6JRWcOi8CJd5jZsDdHs07joJ0cIgVTJYrdwr7EhULkf8Xf3/1h3Q1dVBxrdKboty9JV/N3fvaLg6DcJf2c+Qce2K4N55ad8sdHFqgqDo5FK3z9Rz+OdcqvDMlVuZsoGx6AkyH9HgW4ALJYCeUkJzmQ29CbqOmcVle/pzgj+aS5qix/iS/2GBcBcDetEjbBnUGLb2LmjVsReGTIpE7J5/cOeZMh/nHQpDS3vVO6dlfSgG9EKkbwiGi8sgbHlQiOyDYfCUemPuqWTM8rJH22nJeHj0D7RzbIfwg6cQqbCxKP/MLHhJSAZ9EDBkEuav24Nzd0pcHjlAd0bIlrsKLrv3kDC6ORwZoMszXfkFTLb1v3SnaA4ubY9EWEgAvN2ksLNvgrY9QjA1Oh7JN5+IvBwUAL0oA3H9ndG49ypc58GhREgKb8Wir4sU/jGlXhJPU/dj646TogFCoT06Anpx/mNkZr1Q0q6U6JJ3GjPaSSBt5ASp13gkpheg+FkyNqw8inuCh4SsLoYAdKX6qASSMgA97zzm+dijWWiiyE1NgX7Cd9Vr6IV3NiLYxRZOAStwje+zEkCXNG+Pbt27c3lCKVcodwTMxqFyxVJRVzftr+sC6C8OhsPLjTeLKZ9dHG1hYy82kyk+44HRCbz9OJ8zQTiWaNpC/xXcxIbgpmjWfwNuCrO7AqTFBKCZdzj2lyx4Cs8L/aEM6IX3D2LZzCjsvS2b3XIAL9qMVvQoGWvmRGHPjdLZ7/PMDGS9kAfwgqyHyFLgYZ0A/f4ejHGXoO3U47LF1KJsnN69D4ei/dG4cR+suVXIrRvtGeMB56AITO6osFOUBq3MXNUyWALoobsVbeSyRWYG6AKDaC8UysxF7yoCuvh7eXiUlowdy6YhpKsHnCRSeIzeXrI6rgDoxcV4fmY+Ojs1gtewaCSl3EFW1h2kJEUjxMsJUu8ZOP6E/7ZMK7B3Has/QJejRxFy7p7D3nWzMWba1tJFt6InSI2PQI9mdrCRdMGiS7KNHHknpqGNUxBi78sLiHkCeh6urugNZ0dfRJZsIikqLNQQTuAZdg5TsVO06AH2jGkFiVsP9PFuCr/IM3hKNLQCk0thejK28lv+lc6xCO8mhcR7HFYp3SsJExC3GYevl2yOK0jFIl/Fbf/PcXFJT7i4h2Cboonx2T+I6uECl55ROFdif5aXO2VAl79fLPNLFwG64n35/y+QcS4B0WFB8HQNxkYFd0/tAT0cf0X3hNR9NHaLvlF4MxZBLlJ0nn8Oz0tkrOhBCi7cOq9m6z8v48XIzUjB/o2RmDhhNS48IZOLMxigywFVKbHkO7Ui12WA7hC4EmkaN0vcxbXTu7BtXwrucc/dxuYQZ4VYLoXIOBKFIe1dSrxKbGAjcUa7/pE4cFe84q9vQC9Cdtox7IqLwdywEAR4u0FqawtpSz8MW3IcWYXPcOvYBkQEesBB0gSdx4ZjUGt7uA/bilv5z5E8rR2k3ZcpxJ4Qx3Ip1Yzk6K6tycVeIS6HoilD6f8yzBviCXtxLBeODwqRsT8cPlIpfOeckgEwF6Sr7F2MpV4uxCu5uLquP5pLWiJ0ZwZyr6xGUFNntB+xDAeupmBZT2uwoauTCd1MLnnn5sLbwQuzzvK7n58hdX0IWrn2wKLTmci+dx2XzhzDvoS/sH7lYsyfOQVjg9pBaiNBq1Gq1mb0AOj5mUg9+BeWzRyJ3l4ukEhc8HvwVKw9ehNZ2aIF2cxM3EscCzf7jphzMkPe1PGE9/8WmVwyzyLpmHwsm/y0DQjpOx9nFZ0GSjZblQbnKsLT68lI2BCNOZwMtoDUzhaObp0xZO7fuPOMAF2KgPl7uNyglB9UduxBVHATZnKRA5YKgb4M0GXb4tUvWqiLEqgUbbEEeHIepOHcP6m480QM5OqErKLXZdM2+8bu8A4IQVjkWuw6fRtPC4tReC8BYT5NILFxQAu/MYg5fp/zVX7yzxIEuErQ2L01mjk0weAtGUpTRbGGXnRvDfqQR4s2G1VsW2DSQZnAcIuiEincOyqYL3gzhppzlzbOkIgBvSgL/6wZDi+pI9qOiscNfmpd9ARpR3er3+WZuB2zejqK/NALcXd7KDwkUniH7yuZbRUjJ20Hpvm7wd7GFnbk2unuh+DBIQgdORpjxo7DuHHjMG7sGIwePQqj5+wqnfVUiPe073ddTC6aZUMXQH+GfeNbwsk/BtdLzCrcGgztXXBwgpPEluMHO/Jy8vBCx669ERwyGmEzIrFk0Wh4S5sgcOUVhXUcPQB69mYMcGoMD79BmLJ4K5JvP5PxbuEtxPQse3AnHnYY9FdJHBwRoAubjeT7paiodOb64sIWzP1zDuZMGwQvR3v0WH6jZJZdgCtRfnBs7A6f3iGYXCKDT3hzVMmiqMRROWaQo8QGDsyGLk90zUys6dk8HJneCe1C1+NKejrStT5uIH5SB3hN3K3ebGIkYae2v3icXepLLi63KAsn4lYh4fwDBcEqwuPURCwNH43xUWI3rlJa5Z9ehKCuY7GFptW5N3Fit4bt8WKPiV1JuFBiQy26vx9L/liEvYpTc3EdlX4XIetYDKZGJuIGLxBF2TizfAxGLTqEe7y9W+m90rqX8kMB0vbGYHlCitBPhXcSEbkwSYVnTx6yrp3BgZ2bsGbZIsyfPQMRf4RjMkXFmzQREyaMx/jx4xG+4YICLVWVq99rL5KmoL3XaMSLzAGlbdSlrBdImuSB5iFb8EgLj6sn5+Ow4Yhox3HuDZxMOoCjJ/9BytVbuF/ilqhcl1xcXB2OOXtuKngLFSB1eRC8+saULkQr9GNB2hoM9R2EVeoCVhU9Q3a2Ku+mF7ibcgLJycllHidSH5ashxUifdNI+AYtwTleSVCoj7hthdfjMMa/O3r06IW+o6NxXNQfhTlPkcPzq+I3XhzB3N5BiExWrHc+zi4diIDpSbIIporvWfB/E3m56CIM7Fkxc7PfjB8YDzAeUMcDDNAteDRW16nsOhN4xgOVkwcYoDNAF8wiDAQqJwiwfreefmeAzgCdATrjAcYDVsIDDNCtpCOZlmU9WhbrS9aX5eUBBugM0Jl2xniA8YCV8AADdCvpyPKO6Ow9pg0yHrAeHmCAzgCdaWeMBxgPWAkP/H8sU5UCz1Zd8gAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "48210f5c",
   "metadata": {},
   "source": [
    "### 3.1.1 线性回归的基本要素\n",
    "以⼀个简单的房屋价格预测作为例⼦来解释线性回归的基本要素。这个应⽤的⽬标是预测⼀栋房⼦\n",
    "的售出价格（元）。我们知道这个价格取决于很多因素，如房屋状况、地段、市场⾏情等。为了简单起\n",
    "⻅，这⾥我们假设价格只取决于房屋状况的两个因素，即⾯积（平⽅⽶）和房龄（年）。接下来我们希\n",
    "望探索价格与这两个因素的具体关系\n",
    " \n",
    "### 3.1.1.1 模型定义\n",
    "\n",
    "设房屋的面积为 $x_1$，房龄为 $x_2$，售出价格为 $y$。我们需要建立基于输入 $x_1$ 和 $x_2$ 来计算输出 $y$ 的表达式，也就是模型（model）。顾名思义，线性回归假设输出与各个输入之间是线性关系：\n",
    "$$\n",
    "\\hat{y} = x_1 w_1 + x_2 w_2 + b\n",
    "$$\n",
    "其中 $w_1$ 和 $w_2$ 是权重（weight），$b$ 是偏差（bias），且均为标量。它们是线性回归模型的参数（parameter）。模型输出 $\\hat{y}$ 是线性回归对真实价格 $y$ 的预测或估计。我们通常允许它们之间有一定误差。\n",
    "\n",
    "\n",
    "### 3.1.1.2 模型训练\n",
    "\n",
    "接下来我们需要通过数据来寻找特定的模型参数值，使模型在数据上的误差尽可能小。这个过程叫作模型训练（model training）。下面我们介绍模型训练所涉及的3个要素。\n",
    "\n",
    "#### (1) 训练数据\n",
    "我们通常收集一系列的真实数据，例如多栋房屋的真实售出价格和它们对应的面积和房龄。我们希望在这个数据上面寻找模型参数来使模型的预测价格与真实价格的误差最小。在机器学习术语里，该数据集被称为训练数据集（training data set）或训练集（training set），一栋房屋被称为一个样本（sample），其真实售出价格叫作标签（label），用来预测标签的两个因素叫作特征（feature）。特征用来表征样本的特点。\n",
    "\n",
    "假设我们采集的样本数为 $n$，索引为 $i$ 的样本的特征为 $x_1^{(i)}$ 和 $x_2^{(i)}$，标签为 $y^{(i)}$。对于索引为 $i$ 的房屋，线性回归模型的房屋价格预测表达式为\n",
    "$$\n",
    "\\hat{y}^{(i)} = x_1^{(i)} w_1 + x_2^{(i)} w_2 + b\n",
    "$$\n",
    "\n",
    "#### (2) 损失函数\n",
    "\n",
    "在模型训练中，我们需要衡量价格预测值与真实值之间的误差。通常我们会选取一个非负数作为误差，且数值越小表示误差越小。一个常用的选择是平方函数。它在评估索引为 $i$ 的样本误差的表达式为\n",
    "\n",
    "$$\\ell^{(i)}(w_1, w_2, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2$$\n",
    "\n",
    "其中常数 $\\frac 1 2$ 使对平方项求导后的常数系数为1，这样在形式上稍微简单一些。显然，误差越小表示预测价格与真实价格越相近，且当二者相等时误差为0。给定训练数据集，这个误差只与模型参数相关，因此我们将它记为以模型参数为参数的函数。在机器学习里，将衡量误差的函数称为损失函数（loss function）。这里使用的平方误差函数也称为平方损失（square loss）。\n",
    "\n",
    "通常，我们用训练数据集中所有样本误差的平均来衡量模型预测的质量，即\n",
    "\n",
    "$$\n",
    "\\ell(w_1, w_2, b) =\\frac{1}{n} \\sum_{i=1}^n \\ell^{(i)}(w_1, w_2, b) =\\frac{1}{n} \\sum_{i=1}^n \\frac{1}{2}\\left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\\right)^2\n",
    "$$\n",
    "\n",
    "在模型训练中，我们希望找出一组模型参数，记为 $w_1^*, w_2^*, b^*$，来使训练样本平均损失最小：\n",
    "\n",
    "$$\n",
    "w_1^*, w_2^*, b^* = \\underset{w_1, w_2, b}{\\arg\\min} \\ell(w_1, w_2, b)\n",
    "$$\n",
    "\n",
    "\n",
    "#### (3) 优化算法\n",
    "\n",
    "当模型和损失函数形式较为简单时，上面的误差最小化问题的解可以直接用公式表达出来。这类解叫作解析解（analytical solution）。本节使用的线性回归和平方误差刚好属于这个范畴。然而，大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫作数值解（numerical solution）。\n",
    "\n",
    "在求数值解的优化算法中，小批量随机梯度下降（mini-batch stochastic gradient descent）在深度学习中被广泛使用。它的算法很简单：先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch）$\\mathcal{B}$，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后用此结果与预先设定的一个正数的乘积作为模型参数在本次迭代的减小量。\n",
    "\n",
    "在训练本节讨论的线性回归模型的过程中，模型的每个参数将作如下迭代：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "w_1 &\\leftarrow w_1 -   \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\frac{ \\partial \\ell^{(i)}(w_1, w_2, b)  }{\\partial w_1} = w_1 -   \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}}x_1^{(i)} \\left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\\right),\\\\\n",
    "w_2 &\\leftarrow w_2 -   \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\frac{ \\partial \\ell^{(i)}(w_1, w_2, b)  }{\\partial w_2} = w_2 -   \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}}x_2^{(i)} \\left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\\right),\\\\\n",
    "b &\\leftarrow b -   \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\frac{ \\partial \\ell^{(i)}(w_1, w_2, b)  }{\\partial b} = b -   \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}}\\left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\\right).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "在上式中，$|\\mathcal{B}|$ 代表每个小批量中的样本个数（批量大小，batch size），$\\eta$ 称作学习率（learning rate）并取正数。需要强调的是，这里的批量大小和学习率的值是人为设定的，并不是通过模型训练学出的，因此叫作超参数（hyperparameter）。我们通常所说的“调参”指的正是调节超参数，例如通过反复试错来找到超参数合适的值。在少数情况下，超参数也可以通过模型训练学出。本书对此类情况不做讨论。\n",
    "\n",
    "### 3.1.1.3 模型预测\n",
    "模型训练完成后，我们将模型参数 $w_1, w_2, b$ 在优化算法停止时的值分别记作 $\\hat{w}_1, \\hat{w}_2, \\hat{b}$。注意，这里我们得到的并不一定是最小化损失函数的最优解 $w_1^*, w_2^*, b^*$，而是对最优解的一个近似。然后，我们就可以使用学出的线性回归模型 $x_1 \\hat{w}_1 + x_2 \\hat{w}_2 + \\hat{b}$ 来估算训练数据集以外任意一栋面积（平方米）为$x_1$、房龄（年）为$x_2$的房屋的价格了。这里的估算也叫作模型预测、模型推断或模型测试。\n",
    "\n",
    "\n",
    "## 3.1.2 线性回归的表示方法\n",
    "\n",
    "我们已经阐述了线性回归的模型表达式、训练和预测。下面我们解释线性回归与神经网络的联系，以及线性回归的矢量计算表达式。\n",
    "\n",
    "### 3.1.2.1 神经网络图\n",
    "\n",
    "在深度学习中，我们可以使用神经网络图直观地表现模型结构。为了更清晰地展示线性回归作为神经网络的结构，图3.1使用神经网络图表示本节中介绍的线性回归模型。神经网络图隐去了模型参数权重和偏差。\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "\n",
    "在图3.1所示的神经网络中，输入分别为 $x_1$ 和 $x_2$，因此输入层的输入个数为2。输入个数也叫特征数或特征向量维度。图3.1中网络的输出为 $o$，输出层的输出个数为1。需要注意的是，我们直接将图3.1中神经网络的输出 $o$ 作为线性回归的输出，即 $\\hat{y} = o$。由于输入层并不涉及计算，按照惯例，图3.1所示的神经网络的层数为1。所以，线性回归是一个单层神经网络。输出层中负责计算 $o$ 的单元又叫神经元。在线性回归中，$o$ 的计算依赖于 $x_1$ 和 $x_2$。也就是说，输出层中的神经元和输入层中各个输入完全连接。因此，这里的输出层又叫全连接层（fully-connected layer）或稠密层（dense layer）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c24ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
